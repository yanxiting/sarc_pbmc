---
title: "FastQC on bulk RNAseq data"
author: "Xiting Yan"
date: "05/25/2021"
output:
  html_notebook:
    code_folding: hide
    fig_caption: yes
    highlight: tango
    number_sections: no
    theme: united
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE,echo = TRUE,cache=TRUE,warning=FALSE,message = FALSE,results='hold',cache.lazy = FALSE)
knitr::opts_knit$set(eval.after = 'fig.cap',dev=c('png','postscript'))

library(kableExtra)
library(gdata)
library(knitr)
library(captioner)
library(nlme)
library(rgl)
library(gplots)

knit_hooks$set(webgl = hook_webgl)


table_nums_1 <- captioner::captioner(prefix="Table",levels=1)
figure_nums_1<- captioner::captioner(prefix="Figure",levels=1)


table_nums_2 <- captioner::captioner(prefix="Table",levels=2)
figure_nums_2<- captioner::captioner(prefix="Figure",levels=2)

table_nums_3 <- captioner::captioner(prefix="Table",levels=3)
figure_nums_3 <- captioner::captioner(prefix="Figure",levels=3)

#home.dir<-"/home/yanxiting/driver_Grace"
home.dir<-"/home/xy48"
source(paste(home.dir,"/Rprogram/my_functions.R",sep=""))
output.dir<-file.path(home.dir,"scratch/GRADS/SARC_results/Results_summary_PBMC_hg38")
```


# Background
In this note, we demonstrate how to use R to generate sh file to run FastQC on a given list of fastq files. There are two styles to run the jobs. 
* Run Cutadapt on different samples in parallele (style 1).
* Run Cutadapt on different samples in one thread (style 2).

# FastQC

## Apply FastQC
Input for this style includes:

* data.dir: folder containing a list of folders, each of which contains fastq files for a given sample. no other files should exist under these folders other than the fastq.gz files.
* work.dir: folder where to save the scripts and the FastQC results.
* fastq.filepath: location of the executable file for FastQC.

```{r eval=FALSE}
# This chunck needs to be run on the hpc.
# Since our samples were saved in two different folders, we run this chunck for each data.dir separately.
#data.dir<-"/home/xy48/scratch/Shervin/data/sample_dir_000005540"
work.dir<-file.path(home.dir,"scratch60/Laura_Koth")
data.dir<-file.path(work.dir,"fastq")

fastqc.filepath<-"/home/xy48/scratch_kaminski/public/softwares/FastQC_v0.11.5/fastqc" # This has to be a location on the hpc.

script.dir<-file.path(work.dir,"scripts_FastQC")
output.dir<-file.path(work.dir,"results_FastQC")

if(file.exists(script.dir)==F){
  dir.create(script.dir)
}

if(file.exists(output.dir)==F){
  dir.create(output.dir)
}

jobsub.filepath<-file.path(script.dir,"jobsub.bat")
if(file.exists(jobsub.filepath)){
  file.remove(jobsub.filepath)
}
file.create(jobsub.filepath)

# get the list of folders under data.dir
filenames<-list.files(data.dir)

# we generate one sh file for each sample separately.
for(i in 1:length(filenames)){
  sample.name<-my.element.extract(filenames[i],splitchar="\\.",index=1)
  script.filepath<-file.path(script.dir,paste(sample.name,".sh",sep=""))
  output.subdir<-file.path(output.dir,sample.name)
  if(file.exists(output.subdir)==F){
    dir.create(output.subdir)
  }
  
  # generate the header for the sh file
  cmd.out<-"#!/bin/bash\n"
  cmd.out<-paste(cmd.out,"#SBATCH --partition=day,pi_kaminski\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --job-name=",sample.name,"\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --ntasks=1\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --cpus-per-task=10\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --mem-per-cpu=10G\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --time=1-00:00:00\n",sep="")
  
  fastq.filepath<-file.path(data.dir,filenames[i])
  temp<-paste(fastqc.filepath," -o ",output.subdir," -t 10 ",fastq.filepath,"\n",sep="")
  cmd.out<-paste(cmd.out,paste(temp,collapse="\n"),sep="")
  cat(cmd.out,file=script.filepath,append=F)
  
  cat("sbatch < ",script.filepath,"\n",sep="",file=jobsub.filepath,append=T)
}
system(paste("chmod 700 ",jobsub.filepath,sep=""))

```

## FastQC Summary
We load in the results and generate a summary of the fastQC results.

First, we unzip the zip files generated by FastQC.
```{r}
# These codes were run directy on the HPC

# First, we unzip the FastQC report zip files
result.dir<-"/home/xy48/scratch60/Laura_Koth/results_FastQC"
sample.names<-list.files(result.dir)

for(i in 1:length(sample.names)){
  filenames<-list.files(file.path(result.dir,sample.names[i]))
  filenames<-filenames[grep(".zip",filenames)]
  for(j in 1:length(filenames)){
    unzip(file.path(result.dir,sample.names[i],filenames[j]),exdir=file.path(result.dir,sample.names[i]))
  }
}
```

Second, extract the results across different files and merge them into one single file.
```{r}
# These codes were run directy on the HPC
###########
# Second, we extract the results and export it into a spreadsheet.
source("~/Rprogram/my_functions.R")
result.dir<-"/home/xy48/scratch60/Laura_Koth/results_FastQC"
output.filepath<-"/home/xy48/scratch60/Laura_Koth/FastQC_results_table_b2trimming.txt"
sample.names<-list.files(result.dir)
cmd.out<-cmd.out<-data.frame()
filenames.vect<-character()
for(i in 1:length(sample.names)){
  
  result.subdir<-file.path(result.dir,sample.names[i])
  temp.dirs<-list.dirs(result.subdir,full.names=F,recursive = FALSE)
  input.filenames<-file.path(temp.dirs,"summary.txt")
  filenames.vect<-c(filenames.vect,temp.dirs)
  input.filepath<-file.path(result.subdir,input.filenames)
  
  my.data.1<-data.frame()
  for(j in 1:length(input.filepath)){
    temp.text<-as.matrix(read.table(input.filepath[j],sep="\t",header=F,check.names=F))
    temp.values<-temp.text[,1]
    names(temp.values)<-temp.text[,2]
    if(i==1 & j==1){
      my.rownames<-temp.text[,2]
    }
    my.data.1<-rbind(my.data.1,as.data.frame(t(temp.values)))
  }
  
  input.filenames<-file.path(temp.dirs,"fastqc_data.txt")
  input.filepath<-file.path(result.subdir,input.filenames)
  my.data<-data.frame()
  for(j in 1:length(input.filepath)){
    temp.text<-readLines(input.filepath[j])
    
    # get the total number of reads
    temp.rn<-my.element.extract(temp.text[grep("Total Sequences",temp.text)],splitchar="\t",index=-1)
    total.read.num<-as.numeric(temp.rn)
    # extract the overrepresented sequences
    temp.end.index<-grep(">>END_MODULE",temp.text)
    over.start<-grep(">>Overrepresented sequences",temp.text)
    over.end<-min(temp.end.index[temp.end.index>over.start])
    adapter.start<-grep(">>Adapter Content",temp.text)
    adapter.end<-min(temp.end.index[temp.end.index>adapter.start])
    file.end<-length(temp.text)
    
#    my.temp<-c(my.temp,my.element.extract(temp.text[over.start+2],splitchar="\t",index=1))
    if(temp.text[over.start+1]==">>END_MODULE"){
      my.temp<-data.frame(overrepresented_sequence="")
    }else{
      my.temp<-data.frame(overrepresented_sequence=my.element.extract(temp.text[over.start+2],splitchar="\t",index=1))
    }
    my.temp<-cbind(total.read.num,my.temp)
    colnames(my.temp)[1]<-"total_read_num"
    temp.names<-unlist(strsplit(temp.text[adapter.start+1],split="\t"))
    temp.values<-unlist(strsplit(temp.text[adapter.end-1],split="\t"))
    temp.values<-temp.values[-1]
    names(temp.values)<-temp.names[2:length(temp.names)]
    temp.values<-as.data.frame(t(temp.values))
    my.temp<-cbind(my.temp,temp.values)
    my.data<-rbind(my.data,my.temp)
  }
  my.data<-cbind(my.data.1,my.data)
  
  cmd.out<-rbind(cmd.out,my.data)
} 
temp1<-sapply(filenames.vect,my.element.remove,splitchar="_",index=-1)
temp1<-sapply(temp1,my.element.remove,splitchar="_",index=-1)
rownames(cmd.out)<-temp1

# output the table
cat("filenames\t",file=output.filepath,append=F)
write.table(cmd.out,file=output.filepath,sep="\t",row.names=T,col.names=T,quote=F,append=T)
```

## Conclusions
We did not see significant adapter contamination in the data. Therefore, we'll directly map these reads to human genome.

# STAR mapping

We use STAR to map all the reads to human genome.

## Build STAR Index
We build the index file based on the read length. The original read length in this dataset was 101 bps. After the trimming, the read length was not equal but the longest read length is 51 bps. 

We generate the index file using the following command in terminal.
```
# we ran the index building on a computing node
srun --pty -p pi_kaminski -t 12:00:00 --mem 120Gb bash
STAR  --runMode genomeGenerate --runThreadN 20 --genomeDir /home/xy48/scratch60/Laura_Koth/STAR_index/ --genomeFastaFiles /home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/genome.fa --sjdbGTFfile /home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Annotation/Archives/archive-current/Genes/genes.gtf --sjdbOverhang 50
```

## Mapping

We use STAR to map all the reads to human genome UCSC hg38. This dataset is a single-end data.

```{r}
# this chunck needs to be run on the HPC directly
# There's only one fastq file for each end. Needs to be changed if there are multiple parts.
home.dir<-"/home/xy48"
source(file.path(home.dir,"Rprogram/my_functions.R"))
work.dir<-file.path(home.dir,"scratch60/Laura_Koth")
data.dir<-file.path(work.dir,"fastq")
star.index.dir<-file.path(work.dir,"STAR_index")
sjdb.filepath<-"/home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Annotation/Archives/archive-current/Genes/genes.gtf"

script.dir<-file.path(work.dir,"scripts_STAR")
output.dir<-file.path(work.dir,"results_STAR")

if(file.exists(script.dir)==F){
  dir.create(script.dir)
}

if(file.exists(output.dir)==F){
  dir.create(output.dir)
}

jobsub.filepath<-file.path(script.dir,"jobsub.bat")
if(file.exists(jobsub.filepath)){
  file.remove(jobsub.filepath)
}
file.create(jobsub.filepath)

# In this data, each sample has one fastq file.
filenames<-list.files(data.dir)
temp<-unname(sapply(filenames,my.element.extract,splitchar="_",index=4))
filenames<-filenames[!temp%in%c("UHR","R1")]
# get ride of the two samples with no phenotype assignment

sample.names<-unname(sapply(filenames,my.element.extract,splitchar="\\.",index=1))

for(i in 1:length(sample.names)){
  #data.subdir<-file.path(data.dir,sample.names[i])
  temp1<-my.element.extract(sample.names[i],splitchar="_",index=4)
  temp2<-my.element.extract(sample.names[i],splitchar="_",index=5)
  sample.name<-paste0(temp1,"_",temp2)

  output.subdir<-file.path(output.dir,sample.name)
  if(file.exists(output.subdir)==F){
    dir.create(output.subdir)
  }

  # get the list of folders under data.dir
  fastq.filepath<-file.path(data.dir,filenames[i])
  jobname<-sample.name
  
  script.filepath<-file.path(script.dir,paste(jobname,".sh",sep=""))
  
  # We assume there's only one part
  temp<-"#!/bin/bash\n"
  temp<-paste0(temp,"#SBATCH --partition=pi_kaminski,day\n")
  temp<-paste0(temp,"#SBATCH --job-name=",jobname,"\n")
  temp<-paste0(temp,"#SBATCH --nodes=1 --cpus-per-task=10 --mem=40Gb\n")
  temp<-paste0(temp,"#SBATCH --time=1-00:00:00\n")
  temp<-paste0(temp,"#SBATCH --mail-type=NONE\n")
  temp<-paste0(temp,"#SBATCH --error=",script.filepath,".e%J\n","#SBATCH --output=",script.filepath,".o%J","\n",sep="")

  # If there are multiple fastq files for each end, after --readFilesIn concatenate them using ,
  #cmd.out<-paste(cmd.out,"STAR --readFilesCommand zcat --outSAMtype BAM SortedByCoordinate --outSAMprimaryFlag AllBestScore --bamRemoveDuplicatesType UniqueIdentical --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonical --runThreadN 10 --genomeDir ",star.index.dir," --sjdbGTFfile ",sjdb.filepath," --sjdbOverhang 100 --twopassMode Basic"," --readFilesIn ",paste(filenames.1,collapse=",",sep="")," ",paste(filenames.2,collapse=",",sep="")," --outFileNamePrefix ",file.path(output.subdir,sample.names[i]),sep="")
  temp<-paste(temp,"STAR --readFilesCommand zcat --outSAMtype BAM SortedByCoordinate --outSAMprimaryFlag AllBestScore --bamRemoveDuplicatesType UniqueIdentical --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonical --runThreadN 10 --genomeDir ",star.index.dir," --sjdbGTFfile ",sjdb.filepath," --sjdbOverhang 50 --twopassMode Basic"," --readFilesIn ",fastq.filepath," --outFileNamePrefix ",file.path(output.subdir,sample.name),sep="")

  cat(temp,file=script.filepath,append=F)
  cat("sbatch < ",script.filepath,"\n",sep="",file=jobsub.filepath,append=T)
}
system(paste("chmod 700 ",jobsub.filepath,sep=""))
#system(paste("nohup ",script.filepath," > ",log.filepath," &",sep=""))
```


We submit all the jobs by typing `jobsub.bat` in the terminal. 


## Mapping Summary
We generate a summary of the mapping results on the STAR output files.


```{r}
# These codes were run directy on the HPC
rm(list=ls())
source("/home/xy48/Rprogram/my_functions.R")
work.dir<-"/home/xy48/scratch60/Laura_Koth"
data.dir<-file.path(work.dir,"results_STAR")
output.filepath<-file.path(work.dir,"STAR_mapping_summary.txt")

file.names<-list.files(data.dir)	
sample.names<-file.names
star.matrix<-numeric()
for(i in 1:length(file.names)){
    filepath<-list.files(file.path(data.dir,file.names[i]))
    filepath<-filepath[grep(".final.",filepath)]
    filepath<-file.path(data.dir,file.names[i],filepath)
    
    temp<-readLines(filepath)
    # total number of reads
    temp.vect<-as.numeric(my.element.extract(temp[6],splitchar="\t",index=-1))
    # uniquely mapped reads
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[9],splitchar="\t",index=-1)))
    # uniquely mapped rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[10],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)

    # number of multiple loci mapped reads
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[24],splitchar="\t",index=-1)))
    # multi_maprate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[25],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)

    # number of too many loci
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[26],splitchar="\t",index=-1)))
    # toomanyloci_maprate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[27],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    # ummapped_mismatches_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[29],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    
    # unmapped_tooshort_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[30],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)    
    # unmapped_other_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[31],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    # chimeric reads
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[33],splitchar="\t",index=-1)))
    # chimeric_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[34],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    
    star.matrix<-rbind(star.matrix,temp.vect)
}

rownames(star.matrix)<-sample.names
colnames(star.matrix)<-c("total","mapped_unique","maprate_unique","mapped_multiloci","maprate_multiloci","mapped_toomanyloci","maprate_toomanyloci","unmaprate_mismatches","unmaprate_tooshort","unmaprate_other","chimeric","chimeric_rate")
star.matrix[,c("total","mapped_unique","mapped_multiloci","mapped_toomanyloci","chimeric")]<-star.matrix[,c("total","mapped_unique","mapped_multiloci","mapped_toomanyloci","chimeric")]*2
star.matrix<-cbind(rownames(star.matrix),star.matrix)
colnames(star.matrix)[1]<-"sample_names"
write.table(star.matrix,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)

```

# Count matrices

We generate the raw count and the DESeq2 normalized data based on the mapping results.
```{r}

```
