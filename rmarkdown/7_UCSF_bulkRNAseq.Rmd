---
title: "FastQC on bulk RNAseq data"
author: "Xiting Yan"
date: "05/25/2021"
output:
  html_notebook:
    code_folding: hide
    fig_caption: yes
    highlight: tango
    number_sections: no
    theme: united
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE,echo = TRUE,cache=TRUE,warning=FALSE,message = FALSE,results='hold',cache.lazy = FALSE)
knitr::opts_knit$set(eval.after = 'fig.cap',dev=c('png','postscript'))

library(kableExtra)
library(gdata)
library(knitr)
library(captioner)
library(nlme)
library(rgl)
library(gplots)


knit_hooks$set(webgl = hook_webgl)


table_nums_1 <- captioner::captioner(prefix="Table",levels=1)
figure_nums_1<- captioner::captioner(prefix="Figure",levels=1)


table_nums_2 <- captioner::captioner(prefix="Table",levels=2)
figure_nums_2<- captioner::captioner(prefix="Figure",levels=2)

table_nums_3 <- captioner::captioner(prefix="Table",levels=3)
figure_nums_3 <- captioner::captioner(prefix="Figure",levels=3)

#home.dir<-"/home/yanxiting/driver_Grace"
home.dir<-"/home/xy48"
source(paste(home.dir,"/Rprogram/my_functions.R",sep=""))
output.dir<-file.path(home.dir,"scratch/GRADS/SARC_results/Results_summary_PBMC_hg38")
```


# Background
In this note, we demonstrate how to use R to generate sh file to run FastQC on a given list of fastq files. There are two styles to run the jobs. 
* Run Cutadapt on different samples in parallele (style 1).
* Run Cutadapt on different samples in one thread (style 2).

# FastQC

## Apply FastQC
Input for this style includes:

* data.dir: folder containing a list of folders, each of which contains fastq files for a given sample. no other files should exist under these folders other than the fastq.gz files.
* work.dir: folder where to save the scripts and the FastQC results.
* fastq.filepath: location of the executable file for FastQC.

```{r eval=FALSE}
# This chunck needs to be run on the hpc.
# Since our samples were saved in two different folders, we run this chunck for each data.dir separately.
#data.dir<-"/home/xy48/scratch/Shervin/data/sample_dir_000005540"
work.dir<-file.path(home.dir,"scratch60/Laura_Koth")
data.dir<-file.path(work.dir,"fastq")

fastqc.filepath<-"/home/xy48/scratch_kaminski/public/softwares/FastQC_v0.11.5/fastqc" # This has to be a location on the hpc.

script.dir<-file.path(work.dir,"scripts_FastQC")
output.dir<-file.path(work.dir,"results_FastQC")

if(file.exists(script.dir)==F){
  dir.create(script.dir)
}

if(file.exists(output.dir)==F){
  dir.create(output.dir)
}

jobsub.filepath<-file.path(script.dir,"jobsub.bat")
if(file.exists(jobsub.filepath)){
  file.remove(jobsub.filepath)
}
file.create(jobsub.filepath)

# get the list of folders under data.dir
filenames<-list.files(data.dir)

# we generate one sh file for each sample separately.
for(i in 1:length(filenames)){
  sample.name<-my.element.extract(filenames[i],splitchar="\\.",index=1)
  script.filepath<-file.path(script.dir,paste(sample.name,".sh",sep=""))
  output.subdir<-file.path(output.dir,sample.name)
  if(file.exists(output.subdir)==F){
    dir.create(output.subdir)
  }
  
  # generate the header for the sh file
  cmd.out<-"#!/bin/bash\n"
  cmd.out<-paste(cmd.out,"#SBATCH --partition=day,pi_kaminski\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --job-name=",sample.name,"\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --ntasks=1\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --cpus-per-task=10\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --mem-per-cpu=10G\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --time=1-00:00:00\n",sep="")
  
  fastq.filepath<-file.path(data.dir,filenames[i])
  temp<-paste(fastqc.filepath," -o ",output.subdir," -t 10 ",fastq.filepath,"\n",sep="")
  cmd.out<-paste(cmd.out,paste(temp,collapse="\n"),sep="")
  cat(cmd.out,file=script.filepath,append=F)
  
  cat("sbatch < ",script.filepath,"\n",sep="",file=jobsub.filepath,append=T)
}
system(paste("chmod 700 ",jobsub.filepath,sep=""))

```

## FastQC Summary
We load in the results and generate a summary of the fastQC results.

First, we unzip the zip files generated by FastQC.

```{r}
# These codes were run directy on the HPC

# First, we unzip the FastQC report zip files
result.dir<-"/home/xy48/scratch60/Laura_Koth/results_FastQC"
sample.names<-list.files(result.dir)

for(i in 1:length(sample.names)){
  filenames<-list.files(file.path(result.dir,sample.names[i]))
  filenames<-filenames[grep(".zip",filenames)]
  for(j in 1:length(filenames)){
    unzip(file.path(result.dir,sample.names[i],filenames[j]),exdir=file.path(result.dir,sample.names[i]))
  }
}
```

Second, extract the results across different files and merge them into one single file.

```{r}
# These codes were run directy on the HPC
###########
# Second, we extract the results and export it into a spreadsheet.
source("~/Rprogram/my_functions.R")
result.dir<-"/home/xy48/scratch60/Laura_Koth/results_FastQC"
output.filepath<-"/home/xy48/scratch60/Laura_Koth/FastQC_results_table_b2trimming.txt"
sample.names<-list.files(result.dir)
cmd.out<-cmd.out<-data.frame()
filenames.vect<-character()
for(i in 1:length(sample.names)){
  
  result.subdir<-file.path(result.dir,sample.names[i])
  temp.dirs<-list.dirs(result.subdir,full.names=F,recursive = FALSE)
  input.filenames<-file.path(temp.dirs,"summary.txt")
  filenames.vect<-c(filenames.vect,temp.dirs)
  input.filepath<-file.path(result.subdir,input.filenames)
  
  my.data.1<-data.frame()
  for(j in 1:length(input.filepath)){
    temp.text<-as.matrix(read.table(input.filepath[j],sep="\t",header=F,check.names=F))
    temp.values<-temp.text[,1]
    names(temp.values)<-temp.text[,2]
    if(i==1 & j==1){
      my.rownames<-temp.text[,2]
    }
    my.data.1<-rbind(my.data.1,as.data.frame(t(temp.values)))
  }
  
  input.filenames<-file.path(temp.dirs,"fastqc_data.txt")
  input.filepath<-file.path(result.subdir,input.filenames)
  my.data<-data.frame()
  for(j in 1:length(input.filepath)){
    temp.text<-readLines(input.filepath[j])
    
    # get the total number of reads
    temp.rn<-my.element.extract(temp.text[grep("Total Sequences",temp.text)],splitchar="\t",index=-1)
    total.read.num<-as.numeric(temp.rn)
    # extract the overrepresented sequences
    temp.end.index<-grep(">>END_MODULE",temp.text)
    over.start<-grep(">>Overrepresented sequences",temp.text)
    over.end<-min(temp.end.index[temp.end.index>over.start])
    adapter.start<-grep(">>Adapter Content",temp.text)
    adapter.end<-min(temp.end.index[temp.end.index>adapter.start])
    file.end<-length(temp.text)
    
#    my.temp<-c(my.temp,my.element.extract(temp.text[over.start+2],splitchar="\t",index=1))
    if(temp.text[over.start+1]==">>END_MODULE"){
      my.temp<-data.frame(overrepresented_sequence="")
    }else{
      my.temp<-data.frame(overrepresented_sequence=my.element.extract(temp.text[over.start+2],splitchar="\t",index=1))
    }
    my.temp<-cbind(total.read.num,my.temp)
    colnames(my.temp)[1]<-"total_read_num"
    temp.names<-unlist(strsplit(temp.text[adapter.start+1],split="\t"))
    temp.values<-unlist(strsplit(temp.text[adapter.end-1],split="\t"))
    temp.values<-temp.values[-1]
    names(temp.values)<-temp.names[2:length(temp.names)]
    temp.values<-as.data.frame(t(temp.values))
    my.temp<-cbind(my.temp,temp.values)
    my.data<-rbind(my.data,my.temp)
  }
  my.data<-cbind(my.data.1,my.data)
  
  cmd.out<-rbind(cmd.out,my.data)
} 
temp1<-sapply(filenames.vect,my.element.remove,splitchar="_",index=-1)
temp1<-sapply(temp1,my.element.remove,splitchar="_",index=-1)
rownames(cmd.out)<-temp1

# output the table
cat("filenames\t",file=output.filepath,append=F)
write.table(cmd.out,file=output.filepath,sep="\t",row.names=T,col.names=T,quote=F,append=T)
```

## Conclusions
We did not see significant adapter contamination in the data. Therefore, we'll directly map these reads to human genome.

# STAR mapping

We use STAR to map all the reads to human genome.

## Build STAR Index
We build the index file based on the read length. The original read length in this dataset was 101 bps. After the trimming, the read length was not equal but the longest read length is 51 bps. 

We generate the index file using the following command in terminal.
```
# we ran the index building on a computing node
srun --pty -p pi_kaminski -t 12:00:00 --mem 120Gb bash
STAR  --runMode genomeGenerate --runThreadN 20 --genomeDir /home/xy48/scratch60/Laura_Koth/STAR_index/ --genomeFastaFiles /home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Sequence/WholeGenomeFasta/genome.fa --sjdbGTFfile /home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Annotation/Archives/archive-current/Genes/genes.gtf --sjdbOverhang 50
```

## Mapping

We use STAR to map all the reads to human genome UCSC hg38. This dataset is a single-end data.

```{r}
# this chunck needs to be run on the HPC directly
# There's only one fastq file for each end. Needs to be changed if there are multiple parts.
home.dir<-"/home/xy48"
source(file.path(home.dir,"Rprogram/my_functions.R"))
work.dir<-file.path(home.dir,"scratch60/Laura_Koth")
data.dir<-file.path(work.dir,"fastq")
star.index.dir<-file.path(work.dir,"STAR_index")
sjdb.filepath<-"/home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Annotation/Archives/archive-current/Genes/genes.gtf"

script.dir<-file.path(work.dir,"scripts_STAR")
output.dir<-file.path(work.dir,"results_STAR")

if(file.exists(script.dir)==F){
  dir.create(script.dir)
}

if(file.exists(output.dir)==F){
  dir.create(output.dir)
}

jobsub.filepath<-file.path(script.dir,"jobsub.bat")
if(file.exists(jobsub.filepath)){
  file.remove(jobsub.filepath)
}
file.create(jobsub.filepath)

# In this data, each sample has one fastq file.
filenames<-list.files(data.dir)
temp<-unname(sapply(filenames,my.element.extract,splitchar="_",index=4))
filenames<-filenames[!temp%in%c("UHR","R1")]
# get ride of the two samples with no phenotype assignment

sample.names<-unname(sapply(filenames,my.element.extract,splitchar="\\.",index=1))

for(i in 1:length(sample.names)){
  #data.subdir<-file.path(data.dir,sample.names[i])
  temp1<-my.element.extract(sample.names[i],splitchar="_",index=4)
  temp2<-my.element.extract(sample.names[i],splitchar="_",index=5)
  sample.name<-paste0(temp1,"_",temp2)

  output.subdir<-file.path(output.dir,sample.name)
  if(file.exists(output.subdir)==F){
    dir.create(output.subdir)
  }

  # get the list of folders under data.dir
  fastq.filepath<-file.path(data.dir,filenames[i])
  jobname<-sample.name
  
  script.filepath<-file.path(script.dir,paste(jobname,".sh",sep=""))
  
  # We assume there's only one part
  temp<-"#!/bin/bash\n"
  temp<-paste0(temp,"#SBATCH --partition=pi_kaminski,day\n")
  temp<-paste0(temp,"#SBATCH --job-name=",jobname,"\n")
  temp<-paste0(temp,"#SBATCH --nodes=1 --cpus-per-task=10 --mem=40Gb\n")
  temp<-paste0(temp,"#SBATCH --time=1-00:00:00\n")
  temp<-paste0(temp,"#SBATCH --mail-type=NONE\n")
  temp<-paste0(temp,"#SBATCH --error=",script.filepath,".e%J\n","#SBATCH --output=",script.filepath,".o%J","\n",sep="")

  # If there are multiple fastq files for each end, after --readFilesIn concatenate them using ,
  #cmd.out<-paste(cmd.out,"STAR --readFilesCommand zcat --outSAMtype BAM SortedByCoordinate --outSAMprimaryFlag AllBestScore --bamRemoveDuplicatesType UniqueIdentical --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonical --runThreadN 10 --genomeDir ",star.index.dir," --sjdbGTFfile ",sjdb.filepath," --sjdbOverhang 100 --twopassMode Basic"," --readFilesIn ",paste(filenames.1,collapse=",",sep="")," ",paste(filenames.2,collapse=",",sep="")," --outFileNamePrefix ",file.path(output.subdir,sample.names[i]),sep="")
  temp<-paste(temp,"STAR --readFilesCommand zcat --outSAMtype BAM SortedByCoordinate --outSAMprimaryFlag AllBestScore --bamRemoveDuplicatesType UniqueIdentical --outSAMstrandField intronMotif --outFilterIntronMotifs RemoveNoncanonical --runThreadN 10 --genomeDir ",star.index.dir," --sjdbGTFfile ",sjdb.filepath," --sjdbOverhang 50 --twopassMode Basic"," --readFilesIn ",fastq.filepath," --outFileNamePrefix ",file.path(output.subdir,sample.name),sep="")

  cat(temp,file=script.filepath,append=F)
  cat("sbatch < ",script.filepath,"\n",sep="",file=jobsub.filepath,append=T)
}
system(paste("chmod 700 ",jobsub.filepath,sep=""))
#system(paste("nohup ",script.filepath," > ",log.filepath," &",sep=""))
```


We submit all the jobs by typing `jobsub.bat` in the terminal. 


## Mapping Summary
We generate a summary of the mapping results on the STAR output files.


```{r}
# These codes were run directy on the HPC
rm(list=ls())
source("/home/xy48/Rprogram/my_functions.R")
work.dir<-"/home/xy48/scratch60/Laura_Koth"
data.dir<-file.path(work.dir,"results_STAR")
output.filepath<-file.path(work.dir,"STAR_mapping_summary.txt")

file.names<-list.files(data.dir)	
sample.names<-file.names
star.matrix<-numeric()
for(i in 1:length(file.names)){
    filepath<-list.files(file.path(data.dir,file.names[i]))
    filepath<-filepath[grep(".final.",filepath)]
    filepath<-file.path(data.dir,file.names[i],filepath)
    
    temp<-readLines(filepath)
    # total number of reads
    temp.vect<-as.numeric(my.element.extract(temp[6],splitchar="\t",index=-1))
    # uniquely mapped reads
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[9],splitchar="\t",index=-1)))
    # uniquely mapped rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[10],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)

    # number of multiple loci mapped reads
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[24],splitchar="\t",index=-1)))
    # multi_maprate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[25],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)

    # number of too many loci
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[26],splitchar="\t",index=-1)))
    # toomanyloci_maprate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[27],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    # ummapped_mismatches_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[29],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    
    # unmapped_tooshort_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[30],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)    
    # unmapped_other_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[31],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    # chimeric reads
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(temp[33],splitchar="\t",index=-1)))
    # chimeric_rate
    temp.vect<-c(temp.vect,as.numeric(my.element.extract(my.element.extract(temp[34],splitchar="\t",index=-1),splitchar="%",index=1))*0.01)
    
    star.matrix<-rbind(star.matrix,temp.vect)
}

rownames(star.matrix)<-sample.names
colnames(star.matrix)<-c("total","mapped_unique","maprate_unique","mapped_multiloci","maprate_multiloci","mapped_toomanyloci","maprate_toomanyloci","unmaprate_mismatches","unmaprate_tooshort","unmaprate_other","chimeric","chimeric_rate")
star.matrix[,c("total","mapped_unique","mapped_multiloci","mapped_toomanyloci","chimeric")]<-star.matrix[,c("total","mapped_unique","mapped_multiloci","mapped_toomanyloci","chimeric")]*2
star.matrix<-cbind(rownames(star.matrix),star.matrix)
colnames(star.matrix)[1]<-"sample_names"
write.table(star.matrix,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)

```

# Count matrices

We generate the raw count and the DESeq2 normalized data based on the mapping results.

## Raw count matrix

First, we generate the raw count for each sample separately.
```{r rawcount_persample.R}
library(Rsubread)
library(edgeR)
source("~/Rprogram/my_functions.R")

#output.dir<-"/home/xy48/scratch60/Laura_Koth/results_rawcounts"
#tophat.dir<-"/home/xy48/scratch60/Laura_Koth/results_STAR"
#j=1

###############################
# load in the IDs that need to be switched with each other
dir.list<-list.files(tophat.dir)
count.table<-numeric()

result.dirs<-dir.list
#for(j in 1:length(result.dirs)){

sample.name<-result.dirs[j]

temp.files<-list.files(file.path(tophat.dir,result.dirs[j]))
temp.files<-temp.files[grep("out.bam",temp.files)]
bam.filepath<-file.path(tophat.dir,result.dirs[j],temp.files)

temp<-featureCounts(bam.filepath,annot.inbuilt="hg38",annot.ext="/home/ysm/xiting_yan/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Annotation/Archives/archive-2015-08-14-08-18-15/Genes/genes.gtf",isGTFAnnotationFile=T,GTF.featureType="exon",GTF.attrType="gene_id",useMetaFeatures=T,allowMultiOverlap=T,nthreads=1,countMultiMappingReads=T)

anno.matrix<-temp[[2]]
count.table<-cbind(count.table,temp[[1]])

colnames(count.table)<-sample.name

cmd.out<-cbind(anno.matrix,count.table)
output.filepath<-file.path(output.dir,paste(sample.name,"_rawcounts.txt",sep=""))
write.table(cmd.out,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)
#}
```

We generate the sh file to apply the codes above to each sample in parallele.
```{r}
source("/home/xy48/Rprogram/my_functions.R")

r.filepath<-"/home/xy48/scratch60/Laura_Koth/rawcount_persample.R"
tophat.dir<-"/home/xy48/scratch60/Laura_Koth/results_STAR"
work.dir<-"/home/xy48/scratch60/Laura_Koth"

script.dir<-file.path(work.dir,"scripts_rawcounts_hg38")
output.dir<-file.path(work.dir,"results_rawcounts_hg38")

if(file.exists(script.dir)==F){
dir.create(script.dir)
}

if(file.exists(output.dir)==F){
dir.create(output.dir)
}


jobsub.filepath<-file.path(script.dir,"jobsub.bat")
if(file.exists(jobsub.filepath)){
file.remove(jobsub.filepath)
}
file.create(jobsub.filepath)

filenames<-list.files(tophat.dir)
sample.names<-filenames

for(i in 1:length(sample.names)){

script.filepath<-file.path(script.dir,paste(sample.names[i],".sh",sep=""))

# generate the header for slurm
cmd.out<-"#!/bin/bash\n#SBATCH --partition=day,pi_kaminski,week\n#SBATCH --ntasks=1 --nodes=1 --cpus-per-task=1\n#SBATCH --mem=8152\n#SBATCH --time=24:00:00\n#SBATCH --mail-type=NONE\n"
cmd.out<-paste(cmd.out,"#SBATCH --job-name=",sample.names[i],"\n",sep="")
cmd.out<-paste(cmd.out,"#SBATCH --error=",script.filepath,".e%J\n",sep="")
cmd.out<-paste(cmd.out,"#SBATCH --output=",script.filepath,".o%J\n",sep="")

cmd.out<-paste(cmd.out,"R --vanilla<<EOF\n",sep="")
cmd.out<-paste(cmd.out,"tophat.dir<-\"",tophat.dir,"\"\n",sep="")
cmd.out<-paste(cmd.out,"output.dir<-\"",output.dir,"\"\n",sep="")
cmd.out<-paste(cmd.out,"j=",i,"\n",sep="")
cmd.out<-paste(cmd.out,"source(\"",r.filepath,"\")\n",sep="")
cmd.out<-paste(cmd.out,"EOF\n",sep="")

cat(cmd.out,file=script.filepath,append=F)
cat("sbatch < ",script.filepath,"\n",sep="",file=jobsub.filepath,append=T)

system(paste("chmod 700 ",script.filepath,sep=""))
}
system(paste("chmod 700 ",jobsub.filepath,sep=""))

```

We merge the raw count of different samples into the same matrix.
```{r}
# These codes can be run both on a workstation or on grace HPC. It only takes one single thread.
source("~/Rprogram/my_functions.R")

output.dir<-"/home/xy48/scratch60/Laura_Koth/results_rawcounts_hg38"
tophat.dir<-"/home/xy48/scratch60/Laura_Koth/results_STAR"
output.filepath<-"/home/xy48/scratch60/Laura_Koth/rawcounts_all.txt"

###############################
# load in the IDs that need to be switched with each other
dir.list<-list.files(tophat.dir)
dir.samplenames<-dir.list
count.table<-numeric()
result.dirs<-dir.list

for(j in 1:length(result.dirs)){

sample.name<-dir.samplenames[j]
count.filepath<-file.path(output.dir,paste(sample.name,"_rawcounts.txt",sep=""))

temp<-read.table(count.filepath,sep="\t",header=T,check.names=F)
rownames(temp)<-temp[,1]

if(j==1){
anno.matrix<-temp[,1:6]
count.table<-cbind(count.table,temp[,7])
gene.names<-anno.matrix[,1]
}else{
count.table<-cbind(count.table,temp[gene.names,7])
}
}

colnames(count.table)<-dir.samplenames
cmd.out<-cbind(anno.matrix,count.table)
write.table(cmd.out,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)

```



## DESeq2 Normalized count

Based on the raw count matrix, we generate the DESeq2 normalized data.
```{r}
# In this note, we use DESeq2 to normalize the raw counts
# These codes can be run both on the HPC and on local machine. 
# Specification of home.dir decides which machine this is run.

# https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html

####################################
# 0. load in the raw count matrix and generate the 
library(DESeq2)
home.dir<-"/home/yanxiting/driver_Grace"
source(file.path(home.dir,"Rprogram/my_functions.R"))

rawcount.filepath<-file.path(home.dir,"scratch60/Laura_Koth/rawcounts_all.txt")
rawcount.matrix<-read.table(rawcount.filepath,sep="\t",header=T,check.names=F)

annot.matrix<-rawcount.matrix[,1:6]
data.matrix<-rawcount.matrix[,7:ncol(rawcount.matrix)]

# generate the meta data
#meta.data<-readRDS(file.path(home.dir,"scratch/GRADS/SARC_results/Results_summary_PBMC_hg38/baseline/data/clinic_matrix_merged.RDS"),refhook = NULL)
temp.vect<-unname(sapply(colnames(data.matrix),my.element.extract,splitchar="_",index=1))
temp.vect[temp.vect=="duplicate"]<-"sarcoidosis"
meta.data<-data.frame(samples=colnames(data.matrix),disease=temp.vect)
rownames(meta.data)<-colnames(data.matrix)
# match the row names of meta data and the column names of data.matrix
meta.data<-meta.data[colnames(data.matrix),]

dds <- DESeqDataSetFromMatrix(countData = data.matrix, colData = meta.data, design = ~ 1)
#View(counts(dds))
dds <- estimateSizeFactors(dds)
sizeFactors(dds)

normalized_counts <- counts(dds, normalized=TRUE)

cmd.out<-cbind(annot.matrix,normalized_counts)

# output the normalized counts
output.filepath<-file.path(home.dir,"scratch60/Laura_Koth","DESeq2_normalized.txt")
write.table(cmd.out,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)

output.filepath<-file.path(home.dir,"scratch60/Laura_Koth","DESeq2_normalized.RDS")
saveRDS(cmd.out,file=output.filepath,refhook = NULL)

```


## TPM (not run)
First, we calculate the TPMs for each sample separately.
```{r}
# These codes need to be run directly on grace HPC.
star.dir<-"/home/xy48/scratch/Shervin/results_STAR"
gtf.filepath<-"/home/xy48/scratch_kaminski/public/genomes/Homo_sapiens/UCSC/hg38/Annotation/Archives/archive-current/Genes/genes.gtf"
folder.names<-list.files(star.dir)
work.dir<-"/home/xy48/scratch/Shervin"
source("~/Rprogram/my_functions.R")


output.dir<-file.path(work.dir,"results_TPMcalculator_hg38")
script.dir<-file.path(work.dir,"scripts_TPMcalculator_hg38")

if(file.exists(output.dir)==F){
  dir.create(output.dir)
}

if(file.exists(script.dir)==F){
  dir.create(script.dir)
}

jobsub.filepath<-file.path(script.dir,"jobsub.bat")
if(file.exists(jobsub.filepath)){
  file.remove(jobsub.filepath)
}
file.create(jobsub.filepath)

for(i in 1:length(folder.names)){

  temp.name<-my.element.extract(folder.names[i],splitchar="_",index=2)
  
  output.subdir<-file.path(output.dir,temp.name)
  if(file.exists(output.subdir)==F){
    dir.create(output.subdir)
  }
  
  script.filepath<-file.path(script.dir,paste(temp.name,".sh",sep=""))
  bam.filepath<-list.files(file.path(star.dir,folder.names[i]))
  bam.filepath<-bam.filepath[grep("Aligned.sortedByCoord.out.bam",bam.filepath)]
  bam.filepath<-file.path(star.dir,folder.names[i],bam.filepath)
  #bam.filepath<-file.path(star.dir,folder.names[i],"Final.STARBowtie2.bam")
  cmd.out<-"#!/bin/bash\n#SBATCH --partition=day,pi_kaminski\n#SBATCH --ntasks=1 --nodes=1 --cpus-per-task=1\n#SBATCH --mem=49152\n#SBATCH --time=24:00:00\n#SBATCH --mail-type=NONE\n"
  cmd.out<-paste(cmd.out,"#SBATCH --job-name=",temp.name,"\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --error=",script.filepath,".e%J\n",sep="")
  cmd.out<-paste(cmd.out,"#SBATCH --output=",script.filepath,".o%J\n",sep="")
  cmd.out<-paste(cmd.out,"module restore tpmcalculator\n",sep="")
  cmd.out<-paste(cmd.out,"conda activate rnaseq\n",sep="")
  cmd.out<-paste(cmd.out,"cd ",output.subdir,"\n",sep="")
  cmd.out<-paste(cmd.out,"TPMCalculator -g ",gtf.filepath," -b ",bam.filepath,"\n",sep="")
  cat(cmd.out,file=script.filepath,append=F)
  
  cat("sbatch < ",script.filepath,"\n",sep="",file=jobsub.filepath,append=T)
  system(paste("chmod 700 ",script.filepath,"\n",sep=""))
}
system(paste("chmod 700 ",jobsub.filepath,sep=""))

```


Second, we merge the TPMs into matrix.
```{r}
# These codes need to be run on the grace HPC directly.
####################################
# 1. merge the results of TPMs into one big matrix from individual samples
source("~/Rprogram/my_functions.R")
output.filepath<-"/home/xy48/scratch/Shervin/TPM_all.txt"
data.dir<-"/home/xy48/scratch/Shervin/results_TPMcalculator_hg38"
filenames<-list.files(data.dir)

###############################
# load in the IDs that need to be switched with each other
sample.names<-filenames
gene.names<-character()
result.list<-list()
annot.matrix<-character()

for(i in 1:length(filenames)){
cat("i=",i,"\n",sep="")
# check if this sample needs to be corrected or not.
#data.filepath<-file.path(data.dir,filenames[i],"Final.STARBowtie2_genes.out")
data.filepath<-list.files(file.path(data.dir,filenames[i]))
temp<-sapply(data.filepath,my.element.extract,splitchar="\\.",index=-1)
data.filepath<-data.filepath[temp=="out"]
data.filepath<-file.path(data.dir,filenames[i],data.filepath)

temp<-read.table(data.filepath,sep="\t",comment.char="",header=T,as.is=TRUE,check.names=F)
rownames(temp)<-paste(temp[,2],":",temp[,1],sep="")
result.list[[i]]<-temp

temp.names<-setdiff(rownames(temp),gene.names)
annot.matrix<-rbind(annot.matrix,temp[temp.names,1:5])
gene.names<-union(gene.names,rownames(temp))
}

names(result.list)<-sample.names

# generate the TPM matrix
count.table<-numeric()
for(i in 1:length(result.list)){
  count.table<-cbind(count.table,result.list[[i]][gene.names,7])
}
count.table[is.na(count.table)]<-0
colnames(count.table)<-sample.names


rownames(annot.matrix)<-paste(annot.matrix[,2],":",annot.matrix[,1],sep="")
cmd.out<-cbind(annot.matrix[gene.names,],count.table)
write.table(cmd.out,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)


####################################
# generate the log(TPM+1,base=2)
output.filepath<-"/home/xy48/scratch/Shervin/log2TPM_all.txt"
cmd.out<-cbind(annot.matrix[gene.names,],log(count.table+1,base=2))
write.table(cmd.out,file=output.filepath,append=F,sep="\t",row.names=F,col.names=T,quote=F)


```


# PCA analysis

## DESeq2 (log2) 
We first conduct PCA analysis to identify potential outliers in the UCSF cohort.
```{r}
# load in the normalized count matrix
home.dir<-"/home/yanxiting/driver_Grace"
source(file.path(home.dir,"Rprogram/my_functions.R"))

deseq2.filepath<-file.path(home.dir,"scratch60/Laura_Koth","DESeq2_normalized.RDS")
my.data<-readRDS(deseq2.filepath,refhook = NULL)

anno.data<-my.data[,1:6]
rownames(my.data)<-as.matrix(my.data)[,1]
fpkm.matrix<-my.data[,7:ncol(my.data)]

#log2 transform, if yes, do the analysis on log2(fpkm.matrix+1) to avoid log2(0) transformation
log2.transform<-T
if(log2.transform){
fpkm.matrix<-fpkm.matrix+1
fpkm.matrix<-log(fpkm.matrix,base=2)
}
fpkm<-fpkm.matrix

# filter out genes with no variation and centralize the data 
temp.sd<-apply(fpkm,1,sd)
fpkm<-fpkm[temp.sd>0,]
removed_genes <- rownames(fpkm)[temp.sd<=0] 

#Conduct PCA
fpkm.norm<-my.normalize(fpkm)
my.svd<-svd(fpkm.norm)
cat("The cumulative proportion of variation explained by the top 3 PCs:\n",cumsum(my.svd$d^2/sum(my.svd$d^2))[1:3],"\n")
my.projected<-t(fpkm.norm)%*%my.svd$u
my.distance<-dist(my.projected, method = "euclidean", diag = FALSE, upper = FALSE)
```

Then we visualize the 3D PCA plot.

```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
library(rgl)
temp.vect<-unname(sapply(colnames(fpkm),my.element.extract,splitchar="_",index=1))
temp.vect[temp.vect=="duplicate"]<-"sarcoidosis"
my.colors<-c(rep("blue",ncol(fpkm)))
my.colors[temp.vect=="sarcoidosis"]<-"red"
open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

Load in the UCSF batch information to label the PCA plot using different variables.

```{r}
library(xlsx)
data.filepath<-file.path(home.dir,"scratch/GRADS/SARC_results/Results_summary_PBMC_hg38/baseline/Laura_Koth/ucsf_batch_quality.xlsx")
batch.data<-read.xlsx(data.filepath,sheetName = "Sheet1", header = T,check.names=F)
rownames(batch.data)<-paste(batch.data[,1],"_",batch.data[,2],sep="")

# match the rows of batch.data with columns in fpkm
batch.data<-batch.data[colnames(fpkm),]
```

Label the PCA plot using RNAextractiondate,RNAconcngµl, 260/280, 260/230, plate


RNAconcngµl:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$RNAconcngµl
all.colors<-colorpanel(n=500,low="grey",high="red")
breaks=seq(from=min(my.label),to=max(my.label),length=501)
my.index<-numeric()
for(i in 1:length(my.label)){
  if(my.label[i]==min(my.label)){
    my.index<-c(my.index,1)
  }else{
    temp.index<-max((1:501)[breaks<my.label[i]])
    my.index<-c(my.index,temp.index)
  }
}

my.colors<-all.colors[my.index]

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

260/280:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$`260/280`
all.colors<-colorpanel(n=500,low="grey",high="red")
breaks=seq(from=min(my.label),to=max(my.label),length=501)
my.index<-numeric()
for(i in 1:length(my.label)){
  if(my.label[i]==min(my.label)){
    my.index<-c(my.index,1)
  }else{
    temp.index<-max((1:501)[breaks<my.label[i]])
    my.index<-c(my.index,temp.index)
  }
}

my.colors<-all.colors[my.index]

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

260/230:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$`260/230`
all.colors<-colorpanel(n=500,low="grey",high="red")
breaks=seq(from=min(my.label),to=max(my.label),length=501)
my.index<-numeric()
for(i in 1:length(my.label)){
  if(my.label[i]==min(my.label)){
    my.index<-c(my.index,1)
  }else{
    temp.index<-max((1:501)[breaks<my.label[i]])
    my.index<-c(my.index,temp.index)
  }
}

my.colors<-all.colors[my.index]

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

plate:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$plate
my.colors<-my.color.gen.cat(my.label)$color.num

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

date:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$RNAextractiondate
my.colors<-my.color.gen.cat(my.label)$color.num

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```
## DESeq2 (no log2) 

We first conduct PCA analysis to identify potential outliers in the UCSF cohort.

```{r}
# load in the normalized count matrix
home.dir<-"/home/yanxiting/driver_Grace"
source(file.path(home.dir,"Rprogram/my_functions.R"))

deseq2.filepath<-file.path(home.dir,"scratch60/Laura_Koth","DESeq2_normalized.RDS")
my.data<-readRDS(deseq2.filepath,refhook = NULL)

anno.data<-my.data[,1:6]
rownames(my.data)<-as.matrix(my.data)[,1]
fpkm.matrix<-my.data[,7:ncol(my.data)]

#log2 transform, if yes, do the analysis on log2(fpkm.matrix+1) to avoid log2(0) transformation
log2.transform<-F
if(log2.transform){
fpkm.matrix<-fpkm.matrix+1
fpkm.matrix<-log(fpkm.matrix,base=2)
}
fpkm<-fpkm.matrix

# filter out genes with no variation and centralize the data 
temp.sd<-apply(fpkm,1,sd)
fpkm<-fpkm[temp.sd>0,]
removed_genes <- rownames(fpkm)[temp.sd<=0] 

#Conduct PCA
fpkm.norm<-my.normalize(fpkm)
my.svd<-svd(fpkm.norm)
cat("The cumulative proportion of variation explained by the top 3 PCs:\n",cumsum(my.svd$d^2/sum(my.svd$d^2))[1:3],"\n")
my.projected<-t(fpkm.norm)%*%my.svd$u
my.distance<-dist(my.projected, method = "euclidean", diag = FALSE, upper = FALSE)
```

Then we visualize the 3D PCA plot.

```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
library(rgl)
temp.vect<-unname(sapply(colnames(fpkm),my.element.extract,splitchar="_",index=1))
temp.vect[temp.vect=="duplicate"]<-"sarcoidosis"
my.colors<-c(rep("blue",ncol(fpkm)))
my.colors[temp.vect=="sarcoidosis"]<-"red"
open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

Load in the UCSF batch information to label the PCA plot using different variables.

```{r}
library(xlsx)
data.filepath<-file.path(home.dir,"scratch/GRADS/SARC_results/Results_summary_PBMC_hg38/baseline/Laura_Koth/ucsf_batch_quality.xlsx")
batch.data<-read.xlsx(data.filepath,sheetName = "Sheet1", header = T,check.names=F)
rownames(batch.data)<-paste(batch.data[,1],"_",batch.data[,2],sep="")

# match the rows of batch.data with columns in fpkm
batch.data<-batch.data[colnames(fpkm),]
```

Label the PCA plot using RNAextractiondate,RNAconcngµl, 260/280, 260/230, plate


RNAconcngµl:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$RNAconcngµl
all.colors<-colorpanel(n=500,low="grey",high="red")
breaks=seq(from=min(my.label),to=max(my.label),length=501)
my.index<-numeric()
for(i in 1:length(my.label)){
  if(my.label[i]==min(my.label)){
    my.index<-c(my.index,1)
  }else{
    temp.index<-max((1:501)[breaks<my.label[i]])
    my.index<-c(my.index,temp.index)
  }
}

my.colors<-all.colors[my.index]

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

260/280:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$`260/280`
all.colors<-colorpanel(n=500,low="grey",high="red")
breaks=seq(from=min(my.label),to=max(my.label),length=501)
my.index<-numeric()
for(i in 1:length(my.label)){
  if(my.label[i]==min(my.label)){
    my.index<-c(my.index,1)
  }else{
    temp.index<-max((1:501)[breaks<my.label[i]])
    my.index<-c(my.index,temp.index)
  }
}

my.colors<-all.colors[my.index]

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

260/230:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$`260/230`
all.colors<-colorpanel(n=500,low="grey",high="red")
breaks=seq(from=min(my.label),to=max(my.label),length=501)
my.index<-numeric()
for(i in 1:length(my.label)){
  if(my.label[i]==min(my.label)){
    my.index<-c(my.index,1)
  }else{
    temp.index<-max((1:501)[breaks<my.label[i]])
    my.index<-c(my.index,temp.index)
  }
}

my.colors<-all.colors[my.index]

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

plate:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$plate
my.colors<-my.color.gen.cat(my.label)$color.num

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```

date:
```{r fig.width=8,fig.height=8,eval=TRUE, cache=FALSE, results='hide', webgl=TRUE}
# visualize the PCA plot in 3D
my.label<-batch.data$RNAextractiondate
my.colors<-my.color.gen.cat(my.label)$color.num

open3d()
par3d(windowRect=c(300,300,300,300))
plot3d(my.projected[,1],my.projected[,2],my.projected[,3],xlab="PC 1",ylab="PC 2",zlab="PC 3",col=my.colors,type="s", size=0.6,box = F,axes = T)
identify3d(my.projected[,1],my.projected[,2],my.projected[,3],labels=colnames(fpkm),n=ncol(fpkm),plot=TRUE)
rglwidget()
```