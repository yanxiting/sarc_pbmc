---
title: "GSEA analysis of SARC associated genes"
author: "Xiting Yan"
date: "10/02/2019"
output:
  html_notebook:
    code_folding: hide
    fig_caption: yes
    highlight: tango
    number_sections: no
    theme: united
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(eval=TRUE,echo = TRUE,cache=TRUE,warning=FALSE,message = FALSE,results='hold',cache.lazy = FALSE)
knitr::opts_knit$set(eval.after = 'fig.cap',dev=c('png','postscript'))


library(circlize)
library(clusterProfiler)
library(corrplot)
library(ComplexHeatmap)
library(dplyr)
library(EnsDb.Hsapiens.v86) 
library(gdata)
library(ggplot2)
library(ggpubr)
library(ggrepel)
library(gplots)
library(grid)
library(gridExtra)
library(gridGraphics)
library(kableExtra)
library(knitr)
library(Matrix)
library(org.Hs.eg.db)
library(parallel)
library(reshape2)
library(scales)
library(Seurat)
library(SingleR)
library(tidyr)
library(tidyverse)
library(viridisLite)
library(xlsx)
library(randomcoloR)
library(kableExtra)
library(gdata)
library(knitr)
library(nlme)
library(rgl)
library(gplots)
library(WGCNA)
library(xlsx)
library(randomcoloR)
library(ComplexHeatmap)

knit_hooks$set(webgl = hook_webgl)

home.dir<-"/home/yanxiting/driver_Grace"
#home.dir<-"/home/xy48"
#source(paste(home.dir,"/Rprogram/my_functions.R",sep=""))
```
# Data Downloading

## sratools
We downloaded the data using SRAtools on grace using the scripts generated by the following codes. We downloaded the sratools from github and installed it on grace with setup. All files downloaded were not zipped so we also zipped each file into fastq.gz file.

```{r}
id.list<-readLines("/Users/yanxiting/Downloads/SRR_Acc_List(2).txt")
temp1<-paste("/home/xy48/scratch_palmer/sratoolkit/sratoolkit.3.0.0-ubuntu64/bin/prefetch.3.0.0 -X 9999999999999 ",id.list,"\n",sep="")
temp2<-paste("/home/xy48/scratch_palmer/sratoolkit/sratoolkit.3.0.0-ubuntu64/bin/fastq-dump.3.0.0 --split-files ./",id.list,".sra\n",sep="")
temp3<-rep("cd /home/xy48/scratch_palmer/SARC_10x/test/sra\n",length(temp1))
temp4<-paste("gzip ./",id.list,"_*.fastq\n",sep="")
temp5<-rep("ssh transfer\n",length(temp1))
cmd.out<-cbind(temp5,temp1,temp3,temp2,temp4)
temp.cmd<-apply(cmd.out,1,paste,collapse="",sep="")
cat(temp.cmd,file="./download_commands.txt",append=F,sep="")

```

## changing names
The cell ranger pipeline recognize fastq file names are formated as [Sample Name]_S1_L00[Lane Number]_[Read Type]_001.fastq.gz. There are 3 files per sample representing I1, R1 and R2 downloaded by sratools, which were named as *_1, *_2 and *_3.fastq files. To correctly run cell ranger on these files, we need to change the fastq.gz names.

```{r}
# this was run on grace.
source("~/Rprogram/my_functions.R")
data.dir<-"/home/xy48/scratch_palmer/SARC_10x/test/sra"
filenames<-list.files(data.dir)
temp<-sapply(filenames,my.element.extract,splitchar="\\.",index=3)
filenames<-filenames[temp=="gz"]
filenames<-filenames[!is.na(filenames)]

for(i in 1:length(filenames)){
  
  if(substr(filenames[i],1,4)=="SRR9"){
  	from.filename<-filenames[i]
  	temp<-my.element.extract(filenames[i],splitchar="\\.",index=1)
  	temp<-my.element.extract(temp,splitchar="_",index=2)
  	if(temp=="1"){
  		to.filename<-paste0(my.element.extract(filenames[i],splitchar="_",index=1),"_S1_L001_I1_001.fastq.gz")
  	}
  	if(temp=="2"){
  		to.filename<-paste0(my.element.extract(filenames[i],splitchar="_",index=1),"_S1_L001_R1_001.fastq.gz")
  	}
  	if(temp=="3"){
  		to.filename<-paste0(my.element.extract(filenames[i],splitchar="_",index=1),"_S1_L001_R2_001.fastq.gz")
  	}
  
  	file.rename(from=file.path(data.dir,from.filename),to=file.path(data.dir,to.filename))
  	cat("from=",file.path(data.dir,from.filename),"\n","to=",file.path(data.dir,to.filename),"\n",sep="")
  }else{
    
  	from.filename<-filenames[i]
  	temp<-my.element.extract(filenames[i],splitchar="\\.",index=1)
  	temp<-my.element.extract(temp,splitchar="_",index=2)
  	if(temp=="1"){
  		to.filename<-paste0(my.element.extract(filenames[i],splitchar="_",index=1),"_S1_L001_R1_001.fastq.gz")
  	}
  	if(temp=="2"){
  		to.filename<-paste0(my.element.extract(filenames[i],splitchar="_",index=1),"_S1_L001_R2_001.fastq.gz")
  	}
  	if(temp=="3"){
  		to.filename<-paste0(my.element.extract(filenames[i],splitchar="_",index=1),"_S1_L001_I1_001.fastq.gz")
  	}
  
  	file.rename(from=file.path(data.dir,from.filename),to=file.path(data.dir,to.filename))
  	cat("from=",file.path(data.dir,from.filename),"\n","to=",file.path(data.dir,to.filename),"\n",sep="")    
    
  }
}
```

## cell ranger


We rsync the fastq.gz files onto farnam under ~/scratch60/SARC_10X/fastq and run cell ranger on the files using commands generated by the following codes.

```{r}
id.list<-readLines("/Users/yanxiting/Downloads/SRR_Acc_List(2).txt")
temp1<-paste("#!/bin/bash\n#SBATCH --time=24:00:00  --ntasks=1 --partition=general --cpus-per-task=8 --mem=80GB --job-name=",id.list," -o /home/xy48/scratch60/SARC_10X/cellranger_scripts/",id.list,".sh.o%J -e /home/xy48/scratch60/SARC_10X/cellranger_scripts/",id.list,".sh.e%J\n",sep="")
temp2<-rep("module load cellranger/5.0.0\nmodule load bcl2fastq2/2-20-0-foss-2018b\n",length(id.list))
temp3<-paste("cd /home/xy48/scratch60/SARC_10X/cellranger_results\n")
temp4<-paste("cellranger count --id=",id.list," --fastqs=/home/xy48/scratch60/SARC_10X/fastq --transcriptome=/home/xy48/scratch60/SARC_10X/refdata-gex-GRCh38-2020-A --localcores=8 --localmem=60 --sample=",id.list,"\n",sep="")
cmd.out<-cbind(temp1,temp2,temp3,temp4)
temp.cmd<-apply(cmd.out,1,paste,collapse="",sep="")
cat(temp.cmd,file="./cellranger_scripts.txt",append=F,sep="")
```


There are samples with multiple runs. We run cellranger aggr to merge the multiple runs into one single nUMI vector.

```{r}
source(file.path(home.dir,"Rprogram/my_functions.R"))
library(xlsx)
home.dir<-"/home/yanxiting/driver_Farnam"
runtable.filepath<-file.path(home.dir,"scratch60/SARC_10X/SraRunTable.txt")
id.filepath<-file.path(home.dir,"scratch60/SARC_10X/scRNA_ids.xlsx")

run.table<-read.table(runtable.filepath,sep="\t",header=T,check.names = F)
id.table<-read.xlsx(id.filepath,sheetIndex = 1,check.names=F)

temp.table<-run.table[run.table$`GEO_Accession (exp)`%in%as.matrix(id.table)[,1],]
temp.list<-split(as.matrix(temp.table)[,1],temp.table$`GEO_Accession (exp)`)

# extract the samples with multiple runs
temp.list<-temp.list[unlist(lapply(temp.list,length))>1]

# find out the fastq part these IDs belong to
temp.filenames<-list.files(file.path(home.dir,"scratch60/SARC_10X"))
temp.filenames<-temp.filenames[grep(".filelist",temp.filenames)]
temp.filenames<-temp.filenames[grep("fastq",temp.filenames)]

file.list<-list()
for(i in 1:length(temp.filenames)){
  temp<-readLines(file.path(home.dir,"scratch60/SARC_10X",temp.filenames[i]))
  temp<-unname(sapply(temp,my.element.extract,splitchar="/",index=-1))
  temp<-unname(sapply(temp,my.element.extract,splitchar="_",index=1))
  temp<-unique(temp)
  file.list[[i]]<-temp
}
names(file.list)<-temp.filenames
temp<-character()
for(i in 1:length(file.list)){
  temp<-c(temp,rep(names(file.list)[i],length(file.list[[i]])))
}

file.list.matrix<-cbind(unlist(file.list),temp)

temp<-list()
for(i in 1:length(temp.list)){
  temp[[i]]<-unique(file.list.matrix[file.list.matrix[,1]%in%temp.list[[i]],2])
}

# transfer the cellranger results back to farnam
# generate the aggregation CSV file
cellranger.dir<-file.path(home.dir,"scratch60/SARC_10X/cellranger_results")
output.dir<-file.path(home.dir,"scratch60/SARC_10X/cellranger_aggr_scripts")

for(i in 1:length(temp.list)){
  output.filepath<-file.path(output.dir,paste(names(temp.list)[i],"_aggr.csv",sep=""))
  # pipeline before cellranger 6.0, use library. Otherwise, use sample_id
  cmd.out<-c("library_id","molecule_h5")
  cmd.out<-rbind(cmd.out,cbind(temp.list[[i]],paste("/home/xy48/scratch60/SARC_10X/cellranger_results/",temp.list[[i]],"/outs/molecule_info.h5",sep="")))
  write.table(cmd.out,file=output.filepath,row.names=F,col.names=F,sep=",",append=F,quote=F)
}

# generate the sh file to run cellranger aggr on the replicated runs of the same sample.
script.dir<-file.path(home.dir,"scratch60/SARC_10X/cellranger_aggr_scripts")
result.dir<-file.path(home.dir,"scratch60/SARC_10X/cellranger_aggr_results")

for(i in 1:length(temp.list)){
  csv.filepath<-file.path(script.dir,paste(names(temp.list)[i],"_aggr.csv",sep=""))
  script.filepath<-file.path(script.dir,paste(names(temp.list)[i],".sh",sep=""))
  cmd.out<-paste("#!/bin/bash\n#SBATCH --time=24:00:00  --ntasks=1 --partition=general --cpus-per-task=1 --mem=80GB --job-name=",names(temp.list)[i]," -o /home/xy48/scratch60/SARC_10X/cellranger_aggr_scripts/",names(temp.list)[i],".sh.o%J -e /home/xy48/scratch60/SARC_10X/cellranger_aggr_scripts/",names(temp.list)[i],".sh.e%J\n",sep="")
  cmd.out<-paste(cmd.out,"module load cellranger/5.0.0\nmodule load bcl2fastq2/2-20-0-foss-2018b\n",sep="")
  cmd.out<-paste(cmd.out,"cd /home/xy48/scratch60/SARC_10X/cellranger_aggr_results\n",sep="")
  cmd.out<-paste(cmd.out,"cellranger aggr --id=",names(temp.list)[i]," --csv=/home/xy48/scratch60/SARC_10X/cellranger_aggr_scripts/",names(temp.list)[i],"_aggr.csv\n",sep="")
  cat(cmd.out,file=script.filepath,append=F)
}

```

We moved the cellranger aggr results back to cellranger_results together with the samples with unique run.

## UMI matrix extraction

We extract the nUMI vector for the samples included in the original paper.


```{r}
home.dir<-"/home/yanxiting/driver_Grace"
source(file.path(home.dir,"Rprogram/my_functions.R"))
library(xlsx)
runtable.filepath<-file.path(home.dir,"scratch_palmer/SARC_10x/SraRunTable.txt")
id.filepath<-file.path(home.dir,"scratch_palmer/SARC_10x/scRNA_ids.xlsx")

run.table<-read.table(runtable.filepath,sep="\t",header=T,check.names = F)
id.table<-read.xlsx(id.filepath,sheetIndex = 1,check.names=F)

my.table<-run.table[run.table$`GEO_Accession (exp)`%in%as.matrix(id.table)[,1],]

filenames<-list.files(file.path(home.dir,"scratch_palmer/SARC_10x/cellranger_results"))

# use Read10x to load in the data
dir.list<-rep("",length(filenames))
sample.names<-character()
for(i in 1:length(filenames)){
  
  if(substr(filenames[i],1,1)=="G"){
    dir.list[i]<-file.path(home.dir,"scratch_palmer/SARC_10x/cellranger_results",filenames[i],"outs","count","filtered_feature_bc_matrix")
  }else{
    dir.list[i]<-file.path(home.dir,"scratch_palmer/SARC_10x/cellranger_results",filenames[i],"outs","filtered_feature_bc_matrix")
  }
  
  if(substr(filenames[i],1,1)=="G"){
    sample.names<-c(sample.names,filenames[i])
  }else{
    sample.names<-c(sample.names,as.matrix(my.table)[my.table$Run==filenames[i],"Sample Name"])
  }
 
}

# duplicated gene symbols will be changed to .1, .2, and so on.
temp<-Read10X(data.dir=dir.list,gene.column=2,cell.column=1)
temp.num<-as.numeric(sapply(colnames(temp),my.element.extract,splitchar="_",index=1))
temp1<-sample.names[temp.num]
temp2<-sapply(colnames(temp),my.element.extract,splitchar="_",index=-1)
colnames(temp)<-paste(temp1,"_",temp2,sep="")
output.filepath<-"/home/yanxiting/driver_Grace/scratch_palmer/SARC_10x/merged_nUMI_45_genenames_Read10X.rds"
saveRDS(temp,file=output.filepath,refhook=NULL)


#gcql1<-CreateSeuratObject(counts=temp)

merged.data<-numeric()
for(i in 1:length(filenames)){
  if(substr(filenames[i],1,1)=="G"){
    matrix.dir<-file.path(home.dir,"scratch_palmer/SARC_10x/cellranger_results",filenames[i],"outs","count","filtered_feature_bc_matrix")
  }else{
    matrix.dir<-file.path(home.dir,"scratch_palmer/SARC_10x/cellranger_results",filenames[i],"outs","filtered_feature_bc_matrix")
  }
  
  barcode.path <- file.path(matrix.dir, "barcodes.tsv.gz")
  features.path <- file.path(matrix.dir, "features.tsv.gz")
  matrix.path <- file.path(matrix.dir, "matrix.mtx.gz")
  mat <- readMM(file = matrix.path)
  feature.names = read.delim(features.path,
                             header = FALSE,
                             stringsAsFactors = FALSE)
  barcode.names = read.delim(barcode.path,
                             header = FALSE,
                             stringsAsFactors = FALSE)
  if(substr(filenames[i],1,1)=="G"){
    sample.name<-filenames[i]
  }else{
    sample.name<-as.matrix(my.table)[my.table$Run==filenames[i],"Sample Name"]
  }
  
  colnames(mat) = paste0(sample.name,"_",barcode.names$V1)
  rownames(mat) = feature.names$V2
  
  if(i==1){
    merged.data<-mat
    gene.names<-rownames(mat)
  }else{
    merged.data<-cbind(merged.data,mat[gene.names,])
  }
}

output.filepath<-"/home/yanxiting/driver_Grace/scratch_palmer/SARC_10x/merged_nUMI_45_genenames.rds"
saveRDS(merged.data,file=output.filepath,refhook=NULL)

```

We transferred the cellranger results back to farnam to extract the nUMI results. We also add the samples with multiple runs into the merged matrix.

```{r eval=FALSE}
# samples with multiple runs have names of the GEO accession number.
source("/home/yanxiting/driver_Farnam/Rprogram/my_functions.R")
library(Matrix)
cellranger.dir<-"/home/yanxiting/driver_Farnam/scratch60/SARC_10X/cellranger_results"
runtable.filepath<-"/home/yanxiting/driver_Farnam/scratch60/SARC_10X/SraRunTable.txt"

# load in the run table
run.table<-read.table(runtable.filepath,sep="\t",header=T,check.names=F,stringsAsFactors = FALSE)

# load in the run names and the GSM IDs under the cell ranger results folder
temp.filenames<-list.files(cellranger.dir)

sample.rep<-temp.filenames[substr(temp.filenames,1,3)=="GSM"]
sample.uni<-temp.filenames[substr(temp.filenames,1,3)!="GSM"]
my.run.table<-run.table[as.matrix(run.table)[,"Sample Name"]%in%sample.rep | as.matrix(run.table)[,"Run"]%in%sample.uni,]
# extract the nUMI matrix
dirnames<-list.files(cellranger.dir)
dirnames<-dirnames[substr(dirnames,1,4)=="SRR1"]

for(i in 1:length(dirnames)){
  run.name<-dirnames[i]
  sample.name<-run.table[run.table[,"Run"]==run.name,"Sample Name"]
  matrix_dir<-file.path(cellranger.dir,dirnames[i],"outs","filtered_feature_bc_matrix")
  barcode.path <- file.path(matrix_dir, "barcodes.tsv.gz")
  features.path <- file.path(matrix_dir, "features.tsv.gz")
  matrix.path <- file.path(matrix_dir, "matrix.mtx.gz")
  mat <- readMM(file = matrix.path)
  feature.names = read.delim(features.path,
                             header = FALSE,
                             stringsAsFactors = FALSE)
  barcode.names = read.delim(barcode.path,
                             header = FALSE,
                             stringsAsFactors = FALSE)
  colnames(mat) = paste0(sample.name,"_",barcode.names$V1)
  rownames(mat) = feature.names$V1
  
  output.filepath<-file.path("/home/yanxiting/driver_Farnam/scratch60/SARC_10X/cellranger_results",paste0(sample.name,"_",run.name,"_nUMI.rds"))
  saveRDS(mat,file=output.filepath,refhook=NULL)
}

```


Since we have limited storage on the hpc, we back up the fastq.gz files and the cell ranger output folders. We extracted the nUMI matrix of each sample separately and deleted all other files to make room. All fastq.gz files and their corresponding cell ranger output folders are backed up on google drive under /Volumes/GoogleDrive/My Drive/GraceBackup/GRADS/SARC_PBMC/SARC_10X.

## Seurat Analysis

We load the data into Seurat for downstream analysis, especially for the integrated analysis.

First, we create the Seurat object and preliminary filtering on genes and
```{r}
# due to the unavailability of the cluster, we ran these codes on tac4 server with the same versions of R and packages
# srun --pty --x11 -p pi_kaminski -t 12:00:00 --ntasks=1 --nodes=1 --cpus-per-task=1 --mem=60152 bash
# module restore seurat
#home.dir<-"/home/yanxiting/driver_Farnam"
home.dir<-"/home/yanxiting/Documents/Research/GRADS_SARC_PBMC"
source("/home/yanxiting/Rprogram/my_functions.R")

#output.dir<-file.path(home.dir,"scratch60/SARC_10X/Seurat")
output.dir<-file.path(home.dir,"scRNA-seq/Seurat")

if(file.exists(output.dir)==F){
dir.create(output.dir)
}

# Load the merged data
merged.data<-readRDS(file.path(home.dir,"Data/merged_nUMI_45_genenames_Read10X.rds"),refhook=NULL)

#geoff.data <- Read10X(data.dir = file.path(data.dir,"outs","filtered_gene_bc_matrices_mex","GRCh38"))
#load(file.path(home.dir,"scratch_kaminski/public/Backup/Jonas/R_objects/10x_ChuppAsthma.mtx.hybrid_gene_symbols_wo_background_03_1119.Robj"))
gcql1 <- CreateSeuratObject(counts = merged.data, project = "SARC_10X",min.cells = 3,  min.features = 200)
gcql1[["percent.mt"]] <- PercentageFeatureSet(gcql1, pattern = "^MT-")

cat("\n")
cat("Originally, there are ",nrow(merged.data)," genes and ",ncol(merged.data)," cells in the data.\n",sep="")
cat("After the first step filtering, there are ",nrow(gcql1@assays$RNA@data)," genes and ",ncol(gcql1@assays$RNA@data)," cells in the filtered data.\n",sep="")

rm(merged.data)
#gc(verbose=F)
invisible(gc())

# load in the phenotype data of all the samples
id.filepath<-file.path(home.dir,"Data/scRNA_ids.xlsx")
runtable.filepath<-file.path(home.dir,"Data/SraRunTable.txt")

run.table<-read.table(runtable.filepath,sep="\t",header=T,check.names = F)
id.table<-read.xlsx(id.filepath,sheetIndex = 1,check.names=F)

# get the sample names for all the cells
my.ident<-unname(sapply(colnames(gcql1@assays$RNA@counts),my.element.extract,splitchar="_",index=1))
names(my.ident)<-colnames(gcql1@assays$RNA@counts)

temp<-split(as.matrix(run.table)[,"study_classification"],as.matrix(run.table)[,"Sample Name"])
temp<-lapply(temp,unique)
my.disease<-unlist(temp[my.ident])

my.samplenames<-my.ident
disease.samplenames<-paste(my.disease,"_",my.samplenames,sep="")

# scRNA-seq QC metric.
#mito.genes1 <- grep(pattern = "^MT-", x = rownames(gcql1@assays$RNA@counts), value = TRUE)
#percent.mito1 <- Matrix::colSums(gcql1@assays$RNA@counts[mito.genes1, ])/Matrix::colSums(gcql1@assays$RNA@counts)

# AddMetaData adds columns to object@meta.data, and is a great place to
# stash QC stats
gcql1 <- AddMetaData(object = gcql1, metadata = my.disease, col.name = "disease")
gcql1 <- AddMetaData(object = gcql1, metadata = my.samplenames, col.name = "sample.names")
gcql1 <- AddMetaData(object = gcql1, metadata = my.ident, col.name = "sample")
gcql1 <- AddMetaData(object = gcql1, metadata = disease.samplenames, col.name = "disease.samplenames")
temp<-rep("pbmc",nrow(gcql1@meta.data))
gcql1 <- AddMetaData(object = gcql1, metadata = temp, col.name = "tissue")

# filter the data to only keep genes present (>0 in >=1% of all the cells) in >=3 subjects
gene.pres<-numeric()
sample.names.unique<-unique(gcql1@meta.data$sample.names)

for(i in 1:length(sample.names.unique)){
  temp.matrix<-gcql1@assays$RNA@counts[,gcql1@meta.data$sample.names==sample.names.unique[i]]
  temp.vect<-apply(temp.matrix>0,1,sum)
  gene.pres<-cbind(gene.pres,temp.vect>=(ncol(temp.matrix)*0.01))
}

gene.names<-rownames(gcql1@assays$RNA@counts)[apply(gene.pres,1,sum)>=3]
gcql1.orig<-gcql1
gcql1<-subset(gcql1.orig,features=gene.names)

cat("After the first and second steps of filtering, there are ",nrow(gcql1@assays$RNA@counts)," genes and ",ncol(gcql1@assays$RNA@counts)," cells in the data.\n",sep="")
```


Second, we had a third filtering step on cells based on the nGene and percent.mito. Here are the plots to help us decide the threshold of the filtering.
```{r fig.width=20,fig.height=10,cache=FALSE}

#g1<-VlnPlot(object = gcql1, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3,group.by="samplenames",combine=T)

g2<-VlnPlot(object = gcql1, features= c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3,group.by = "disease.samplenames",combine=T)
grid.arrange(g2,ncol=1)
```


```{r fig.width=14,fig.height=4,echo=FALSE,cache=FALSE,results='asis'}
# show the 2D scatterplot
g1<-FeatureScatter(gcql1,feature1="nCount_RNA",feature2="percent.mt",group.by = "tissue",pt.size=0.5)
g1<-g1+geom_abline(intercept=10,slope=0,col="red") 

g2<-FeatureScatter(gcql1,feature1="nCount_RNA",feature2="nFeature_RNA",group.by = "tissue",pt.size=0.5)
g2<-g2+geom_abline(intercept=300,slope=0,col="red")
g2<-g2+geom_abline(intercept=6000,slope=0,col="red")

g3<-FeatureScatter(gcql1,feature1="nFeature_RNA",feature2="percent.mt",group.by = "tissue",pt.size=0.5)
g3<-g3+geom_abline(intercept=10,slope=0,col="red")
g3<-g3+geom_vline(xintercept=330,col="red")
g3<-g3+geom_vline(xintercept=6000,col="red")
g<-grid.arrange(g1,g2,g3,ncol=3)
ggsave(filename=file.path(output.dir,"1_datapreprocessing_FeatureScatter.pdf"),plot=g,device="pdf",units = "in",width=14,height=4)
```

```{r}
# only keep cells with nFeature_RNA>=330 or <=6000
#gcql1<-subset(gcql1,subset= nFeature_RNA >= 300 & nFeature_RNA<= 6000 & percent.mt<= 50)
gcql1<-subset(gcql1,subset= nFeature_RNA >= 300 & percent.mt<= 50)
cat("After the third filtering step, we have ",nrow(gcql1@assays$RNA@counts)," genes and ",ncol(gcql1@assays$RNA@counts)," cells.\n",sep="")
```

Third, we normalize the unimputed and save the SAVER imputed data as the normalized data. These data are saved for downstream further processing.

```{r}
# normalize the data and save the results
gcql1 <- NormalizeData(gcql1, normalization.method = "LogNormalize",  scale.factor = 10000)
saveRDS(gcql1, file = file.path(output.dir,"1_normalized_data_unimputed_1.rds"))

#gcql1.saver<-NormalizeData(object = gcql1.saver, normalization.method = "LogNormalize",  scale.factor = 10000)
#saveRDS(gcql1.saver, file = file.path(output.dir,"preprocessed_data_saverimputed_1.rds"))

cat("the preprocessed data for the unimputed data was saved as ",file.path(output.dir,"1_normalized_data_unimputed_1.rds"),"\n",sep="")

cat("After the normalization, there are ",nrow(gcql1@assays$RNA@data)," genes and ",ncol(gcql1@assays$RNA@data)," cells\n",sep="")

#cat("the preprocessed data for the SAVER imputed data was saved as ",file.path(output.dir,"preprocessed_data_saverimputed_1.rds"),"\n",sep="")
```

### Original Cell Clustering

First, we find variable genes.
```{r}
features.n<-2000
home.dir<-"/home/yanxiting/Documents/Research/GRADS_SARC_PBMC"
```

We load in the normalized unimputed data and find the top variable genes for cell clustering. The normalized data was further scaled to remove the effect of nUMI and percent.mito for further cell clustering purpose.

```{r fig.width=10,fig.height=5}
# load in the normalized unimputed data
data.filepath<-file.path(home.dir,"scRNA-seq/Seurat/1_normalized_data_unimputed_1.rds")
output.dir<-file.path(home.dir,"scRNA-seq/Seurat")

if(file.exists(output.dir)==F){
  dir.create(output.dir)
}

gcql1<-readRDS(file = data.filepath, refhook = NULL)
gcql1<-FindVariableFeatures(gcql1,selection.method="vst",nfeatures=features.n)

# Identify the 10 most highly variable genes
top10 <- head(VariableFeatures(gcql1), 10)

# plot variable features with and without labels
plot1 <- VariableFeaturePlot(gcql1)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = TRUE)
CombinePlots(plots = list(plot1, plot2))
```


Then we scale the data to remove the effect from nUMI and percent.mito. Here we decide to scale for all genes so that later on, the heatmap will be generated using the scaled data. 
```{r results='hide'}
#maybe regress cell cycle http://satijalab.org/seurat/cell_cycle_vignette.html
all.genes<-rownames(gcql1)
#gcql1 <- ScaleData(gcql1,features = all.genes, vars.to.regress = c("nCount_RNA", "percent.mt"))
gcql1 <- ScaleData(gcql1)
#output.filepath<-file.path(output.dir,"2_scaled_allgenes_unimputed.rds")
#saveRDS(gcql1, file = output.filepath)
```


We perform the principal component analysis on the variable genes to decide the number of PCs to use for clustering.
```{r}
gcql1 <- RunPCA(object = gcql1, features = VariableFeatures(gcql1), npcs=200,verbose=F)
```


To see if there are PCs that are subject specific, the 2D PCA plots using the top 3 PCs are as follows for the un-imputed data. 
```{r fig.width=10,fig.height=15,cache=FALSE,results='hide'}
#par(mfrow=c(2,2))
fig.1<-DimPlot(object = gcql1, dims = c(1,2), pt.size=0.5)
fig.2<-DimPlot(object = gcql1, dims = c(2,3), pt.size=0.5)
fig.3<-DimPlot(object = gcql1, dims = c(1,3), pt.size=0.5)
grid.arrange(fig.1,fig.2,fig.3,ncol=1)
```

We draw the heatmap of the top genes for each PC.
```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 1:10, cells = 500, balanced = TRUE)
```
```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 11:20, cells = 500, balanced = TRUE)
```

```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 21:30, cells = 500, balanced = TRUE)
```

```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 31:40, cells = 500, balanced = TRUE)
```

```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 41:50, cells = 500, balanced = TRUE)
```

```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 51:60, cells = 500, balanced = TRUE)
```

```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 61:70, cells = 500, balanced = TRUE)
```

```{r fig.width=15,height=80,cache=FALSE}
DimHeatmap(gcql1, dims = 71:80, cells = 500, balanced = TRUE)
```

We use the following Jackstraw plots and the Elbowplot to decide the number of PCs to use for downstream analysis.
```{r fig.width=10,fig.height=40,results='hold'}
gcql1 <- JackStraw(object = gcql1, num.replicate = 100, verbose = TRUE,dims=200)
gcql1 <- ScoreJackStraw(gcql1, dims = 1:200)
```


```{r fig.width=16,fig.height=8,cache=FALSE,results='hide'}
JackStrawPlot(gcql1, dims = 1:100)
```

```{r fig.width=8,fig.height=8,cache=FALSE,results='hide'}
ElbowPlot(object = gcql1,ndims=100)
```

```{r}
pc.num<-46
```

Based on the JackStraw plot and the Elbow plot, we decided to use the top 46 PCs for the unimputed data.

```{r}
saveRDS(gcql1, file = file.path(output.dir,paste("2_dimreduction_data_",length(gcql1@assays$RNA@var.features),"vargenes_pipeline1.rds",sep="")))
# we save the file as preprocessed_data_saver.rds to prevent any mistakes but we change the file name back to preprocessed_data.rds before performing downstream analysis.

cat("We save the R project as\n")
cat("unimputed data:\t",file.path(output.dir,paste("2_dimreduction_data_",length(gcql1@assays$RNA@var.features),"vargenes_pipeline1.rds",sep="")),"\n",sep="")
```

### Data visualization

#### UMAP
To identify potential outlying cells and samples, we first label the tSNE plot using disease_samplenames.
```{r}
########################################################################
# 2. generate the TSNE plot labelled specifically for each sample separately to look for outliers.
# srun --pty --x11 -p pi_kaminski -t 12:00:00 --ntasks=1 --nodes=1 --cpus-per-task=1 --mem=60152 bash
#module load Apps/R/3.4.1-generic
#module load Apps/R/3.4.3-generic

data.filepath<-file.path(output.dir,"2_dimreduction_data_2000vargenes_pipeline1.rds")
gcql1 <- readRDS(file = data.filepath, refhook = NULL)

# generate the TSNE plot labeled by labeling samples with different colors 
sample1<-FindNeighbors(gcql1,dims=1:pc.num)
sample1<-FindClusters(sample1,resolution=1.2)
sample1<-RunUMAP(sample1,dims=1:pc.num)
#sample1<-RunUMAP(sample1,dims=1:pc.num,umap.method="umap-learn")


```

```{r fig.width=10,fig.height=20,fig.cap="UMAP labeled by a). cell clusters, b). sample names and c). disease for the unimputed data.",cache=FALSE,results='hide'}
fig1<-DimPlot(sample1,reduction="umap")
fig2<-DimPlot(sample1,reduction="umap",group.by="disease.samplenames")
fig3<-DimPlot(sample1,reduction="umap",group.by="disease")
grid.arrange(fig1,fig2,fig3,ncol=1)
```

```{r fig.width=10,fig.height=20,fig.cap="UMAP labeled by a). cell clusters, b). sample names and c). disease for the unimputed data.",cache=FALSE,results='hide'}
pc.num<-46
# generate the TSNE plot labeled by labeling samples with different colors 
sample1<-FindNeighbors(gcql1,dims=1:pc.num)
sample1<-FindClusters(sample1,resolution=1.2)
sample1<-RunUMAP(sample1,dims=1:pc.num)
#sample1<-RunUMAP(sample1,dims=1:pc.num,umap.method="umap-learn")
fig1<-DimPlot(sample1,reduction="umap")
fig2<-DimPlot(sample1,reduction="umap",group.by="disease.samplenames")
fig3<-DimPlot(sample1,reduction="umap",group.by="disease")
grid.arrange(fig1,fig2,fig3,ncol=1)
```
#### tSNE plot

```{r eval=FALSE}
pc.num<-35
sample1 <- RunTSNE(sample1, dims= 1:pc.num)
```

```{r fig.width=10,fig.height=20,fig.cap="tSNE plots labeled by a). cell clusters, b). sample names and c). disease for the unimputed data.",cache=FALSE,results='hide'}
fig1<-DimPlot(sample1,reduction="tsne")
fig2<-DimPlot(sample1,reduction="tsne",group.by="disease.samplenames")
fig3<-DimPlot(sample1,reduction="tsne",group.by="disease")
grid.arrange(fig1,fig2,fig3,ncol=1)
```

#### data saving
```{r}
saveRDS(sample1, file = file.path(output.dir,paste("2_visualization_data_",length(gcql1@assays$RNA@var.features),"vargenes_pipeline1.rds",sep="")))
cat("We saved the seurat object with UMAP and tSNE as ",file.path(output.dir,paste("2_visualization_data_",length(sample1@assays$RNA@var.features),"vargenes_pipeline1.rds",sep="")),"\n",sep="")
```

### Cell Typing

```{r}
my.distinct.colors<-c('#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000')
```

To describe the cell types captured in the data, the integrated analysis may provide cleaner results. Therefore, we conduct the integrated analysis of all the asthma 10X data using Seurat V3.1 in this note to reduce the subject effect in the data visulization and the trajectory analysis at least. 

#### Data Loading
```{r data_loading,results='hold'}
########################################################
# 1. load in the singler object
home.dir<-"/home/yanxiting/Documents/Research/GRADS_SARC_PBMC"
data.dir<-file.path(home.dir,"scRNA-seq/Seurat")
sample1<-readRDS(file.path(data.dir,"2_visualization_data_2000vargenes_pipeline1.rds"),refhook = NULL)

sample1.raw<-sample1
```

#### integrating data

Split the whole dataset based on subject ID (fresh and DSMO samples from the same subject are considered as one sample). Find anchors to integrate all the datasets together.
```{r}
sample1.list<-SplitObject(sample1.raw,split.by="sample.names")
sample1.list<-lapply(X=sample1.list,FUN=function(x){
  x<-NormalizeData(x)
  x<-FindVariableFeatures(x,selection.method="vst",nfeatures=2000)
})
temp.cellnum<-unlist(lapply(sample1.list,ncol))
#sample1.list<-sample1.list[temp.cellnum>=40]
# increase the global maxSize
options(future.globals.maxSize= 4194304000)
features <- SelectIntegrationFeatures(object.list = sample1.list)
#sample1.list <- lapply(X = sample1.list, FUN = function(x) {
#    x <- ScaleData(x, features = features, verbose = FALSE)
#    x <- RunPCA(x, features =features, npcs=40,verbose=F)
#})
#sample1.anchors<-FindIntegrationAnchors(sample1.list[temp.cellnum>=92],k.filter=92,dims=1:40,verbose=FALSE)
sample1.anchors<-FindIntegrationAnchors(object.list=sample1.list[temp.cellnum>=700],anchor.features=features, reduction="rpca",k.filter=40,dims=1:40,verbose=FALSE)
#sample1.combined<-IntegrateData(anchorset=sample1.anchors,features.to.integrate=rownames(sample1.raw@assays$RNA@counts),dims=1:40,verbose=FALSE)
#,k.filter=40,dims=1:40
sample1.combined<-IntegrateData(anchorset=sample1.anchors,verbose=FALSE,k.weight = 45)
```


```{r}
output.dir<-file.path(home.dir,"scRNA-seq/Seurat")
dir.create(file.path(output.dir,"integrated_analysis"))
output.filepath<-file.path(output.dir,"integrated_analysis","seurat_object_integrated_allcells.rds")
saveRDS(sample1.combined,file=output.filepath)
cat("We saved the integrated data for all cells as ",output.filepath,"\n",sep="")

output.filepath<-file.path(output.dir,"integrated_analysis","seurat_object_original_allcells.rds")
saveRDS(sample1.raw,file=output.filepath)
cat("We saved the original data for all cells as ",output.filepath,"\n",sep="")
```

Cluster the cells using the integrated data.

```{r}
DefaultAssay(sample1.combined) <- "integrated"
# Run the standard workflow for visualization and clustering
sample1.combined <- ScaleData(sample1.combined, verbose = FALSE)
sample1.combined <- RunPCA(sample1.combined, npcs = 40, verbose = FALSE)
# t-SNE and Clustering
sample1.combined <- RunUMAP(sample1.combined, reduction = "pca", dims = 1:40)
sample1.combined <- FindNeighbors(sample1.combined, reduction = "pca", dims = 1:40)
sample1.combined <- FindClusters(sample1.combined, resolution = 1.2)
```

We save the result in a rds file.
```{r}
output.subdir<-file.path(output.dir,"integrated_analysis")
if(file.exists(output.subdir)==F){
  dir.create(output.subdir)
}

output.filepath<-file.path(output.subdir,"seurat_object_integrated_allcells_cellclustering_noSingleR.rds")
saveRDS(sample1.combined,file=output.filepath)
cat("We saved the seurat object of the integrated data with cell clustering results only as ",output.filepath,"\n",sep="")
```


#### Visualizing integrated data

```{r,fig.width=8,fig.height=20}
library(cowplot)
p1 <- DimPlot(sample1.combined, reduction = "umap", group.by = "sample.names")
p2 <- DimPlot(sample1.combined, reduction = "umap", label = TRUE)
#p3<-DimPlot(sample1.combined, reduction = "umap", group.by="singler.hpca.cluster.merged", label = TRUE,cols=my.distinct.colors)
#p4<-DimPlot(sample1.combined, reduction = "umap", group.by="singler.hpca.cluster", label = TRUE,cols=my.distinct.colors)
p5<-DimPlot(sample1.combined, reduction = "umap", group.by="disease", label = TRUE,cols=my.distinct.colors)
#plot_grid(p2, p1, p3,p4,p5,ncol=1)
plot_grid(p2, p1,p5,ncol=1)
```

```{r,fig.width=4,fig.height=60}
# find out the samples with small number of cells and try to see where they are on the UMAP
temp.cellnum<-table(sample1.combined@meta.data$sample.names)
temp.names<-names(temp.cellnum)
temp.cellnum<-as.numeric(temp.cellnum)
names(temp.cellnum)<-temp.names
temp.samples<-names(temp.cellnum)[temp.cellnum<=14000]
temp.samples<-names(sort(temp.cellnum[temp.samples],decreasing=F))

fig.list<-list()
for(i in 1:length(temp.samples)){
#  temp.color<-rep("grey",nrow(sample1.combined@meta.data))
#  temp.color[sample1.combined@meta.data$sample.names==temp.samples[i]]<-"red"
  fig.list[[i]]<-DimPlot(sample1.combined, reduction = "umap",cells.highlight=rownames(sample1.combined@meta.data)[sample1.combined@meta.data$sample.names==temp.samples[i]],sizes.highlight=0.2)+labs(title=paste0(temp.samples[i],":",temp.cellnum[temp.samples[i]]))
}

#do.call("grid.arrange", c(fig.list, nrow=length(fig.list)))
output.filepath<-file.path(output.dir,"umap_integrated_courtney_persample.pdf")

ggsave(
   filename = output.filepath, 
   plot = marrangeGrob(fig.list, nrow=1, ncol=1), 
   width = 6, height = 6
)

cat("The UMAP of each sample highlighted has been saved as ",output.filepath,"\n",sep="")

#pdf(output.filepath, onefile = TRUE)
#for (i in seq(length(fig.list))) {
#  do.call("grid.arrange", fig.list[[i]])  
#}
#dev.off()
```
#### Integrate using Azimuth

We uploaded the seurat_object_original_allcells.rds onto Azimuth website and map them to the reference human PBMC data. We downloaded the predicted cell types to compare to the predictions by Amy's data.
```{r eval=FALSE}
# these are codes downloaded from the Azimuth website as analysis.R codes
#!/usr/bin/env Rscript

# Ensure Seurat v4.0 or higher is installed
if (packageVersion(pkg = "Seurat") < package_version(x = "4.0.0")) {
  stop("Mapping datasets requires Seurat v4 or higher.", call. = FALSE)
}

# Ensure glmGamPoi is installed
if (!requireNamespace("glmGamPoi", quietly = TRUE)) {
  if (!requireNamespace("BiocManager", quietly = TRUE)) {
    BiocManager::install("glmGamPoi")
  }
}

# Ensure Azimuth is installed
if (packageVersion(pkg = "Azimuth") < package_version(x = "0.3.1")) {
  stop("Please install azimuth - remotes::install_github('satijalab/azimuth')", call. = FALSE)
}

library(Seurat)
library(Azimuth)

# Download the Azimuth reference and extract the archive

# Load the reference
# Change the file path based on where the reference is located on your system.
reference <- LoadReference(path = "https://seurat.nygenome.org/azimuth/references/v1.0.0/human_pbmc")

# Load the query object for mapping
# Change the file path based on where the query file is located on your system.
query <- LoadFileInput(path = "seurat_object_original_allcells.rds")

# Calculate nCount_RNA and nFeature_RNA if the query does not
# contain them already
if (!all(c("nCount_RNA", "nFeature_RNA") %in% c(colnames(x = query[[]])))) {
    calcn <- as.data.frame(x = Seurat:::CalcN(object = query))
    colnames(x = calcn) <- paste(
      colnames(x = calcn),
      "RNA",
      sep = '_'
    )
    query <- AddMetaData(
      object = query,
      metadata = calcn
    )
    rm(calcn)
}

# Calculate percent mitochondrial genes if the query contains genes
# matching the regular expression "^MT-"
if (any(grepl(pattern = '^MT-', x = rownames(x = query)))) {
  query <- PercentageFeatureSet(
    object = query,
    pattern = '^MT-',
    col.name = 'percent.mt',
    assay = "RNA"
  )
}

# Filter cells based on the thresholds for nCount_RNA and nFeature_RNA
# you set in the app
cells.use <- query[["nCount_RNA", drop = TRUE]] <= 67269 &
  query[["nCount_RNA", drop = TRUE]] >= 457 &
  query[["nFeature_RNA", drop = TRUE]] <= 7761 &
  query[["nFeature_RNA", drop = TRUE]] >= 300

# If the query contains mitochondrial genes, filter cells based on the
# thresholds for percent.mt you set in the app
if ("percent.mt" %in% c(colnames(x = query[[]]))) {
  cells.use <- cells.use & (query[["percent.mt", drop = TRUE]] <= 100 &
    query[["percent.mt", drop = TRUE]] >= 0)
}

# Remove filtered cells from the query
query <- query[, cells.use]

# Preprocess with SCTransform
query <- SCTransform(
  object = query,
  assay = "RNA",
  new.assay.name = "refAssay",
  residual.features = rownames(x = reference$map),
  reference.SCT.model = reference$map[["refAssay"]]@SCTModel.list$refmodel,
  method = 'glmGamPoi',
  ncells = 2000,
  n_genes = 2000,
  do.correct.umi = FALSE,
  do.scale = FALSE,
  do.center = TRUE
)

# Find anchors between query and reference
anchors <- FindTransferAnchors(
  reference = reference$map,
  query = query,
  k.filter = NA,
  reference.neighbors = "refdr.annoy.neighbors",
  reference.assay = "refAssay",
  query.assay = "refAssay",
  reference.reduction = "refDR",
  normalization.method = "SCT",
  features = intersect(rownames(x = reference$map), VariableFeatures(object = query)),
  dims = 1:50,
  n.trees = 20,
  mapping.score.k = 100
)

# Transfer cell type labels and impute protein expression
#
# Transferred labels are in metadata columns named "predicted.*"
# The maximum prediction score is in a metadata column named "predicted.*.score"
# The prediction scores for each class are in an assay named "prediction.score.*"
# The imputed assay is named "impADT" if computed

refdata <- lapply(X = "celltype.l2", function(x) {
  reference$map[[x, drop = TRUE]]
})
names(x = refdata) <- "celltype.l2"
if (TRUE) {
  refdata[["impADT"]] <- GetAssayData(
    object = reference$map[['ADT']],
    slot = 'data'
  )
}
query <- TransferData(
  reference = reference$map,
  query = query,
  dims = 1:50,
  anchorset = anchors,
  refdata = refdata,
  n.trees = 20,
  store.weights = TRUE
)

# Calculate the embeddings of the query data on the reference SPCA
query <- IntegrateEmbeddings(
  anchorset = anchors,
  reference = reference$map,
  query = query,
  reductions = "pcaproject",
  reuse.weights.matrix = TRUE
)

# Calculate the query neighbors in the reference
# with respect to the integrated embeddings
query[["query_ref.nn"]] <- FindNeighbors(
  object = Embeddings(reference$map[["refDR"]]),
  query = Embeddings(query[["integrated_dr"]]),
  return.neighbor = TRUE,
  l2.norm = TRUE
)

# The reference used in the app is downsampled compared to the reference on which
# the UMAP model was computed. This step, using the helper function NNTransform,
# corrects the Neighbors to account for the downsampling.
query <- NNTransform(
  object = query,
  meta.data = reference$map[[]]
)

# Project the query to the reference UMAP.
query[["proj.umap"]] <- RunUMAP(
  object = query[["query_ref.nn"]],
  reduction.model = reference$map[["refUMAP"]],
  reduction.key = 'UMAP_'
)


# Calculate mapping score and add to metadata
query <- AddMetaData(
  object = query,
  metadata = MappingScore(anchors = anchors),
  col.name = "mapping.score"
)

# VISUALIZATIONS

# First predicted metadata field, change to visualize other predicted metadata
id <- "celltype.l2"[1]
predicted.id <- paste0("predicted.", id)

# DimPlot of the reference
DimPlot(object = reference$plot, reduction = "refUMAP", group.by = id, label = TRUE) + NoLegend()

# DimPlot of the query, colored by predicted cell type
DimPlot(object = query, reduction = "proj.umap", group.by = predicted.id, label = TRUE) + NoLegend()

# Plot the score for the predicted cell type of the query
FeaturePlot(object = query, features = paste0(predicted.id, ".score"), reduction = "proj.umap")
VlnPlot(object = query, features = paste0(predicted.id, ".score"), group.by = predicted.id) + NoLegend()

# Plot the mapping score
FeaturePlot(object = query, features = "mapping.score", reduction = "proj.umap")
VlnPlot(object = query, features = "mapping.score", group.by = predicted.id) + NoLegend()

# Plot the prediction score for the class CD16 Mono
FeaturePlot(object = query, features = "CD16 Mono", reduction = "proj.umap")
VlnPlot(object = query, features = "CD16 Mono", group.by = predicted.id) + NoLegend()

# Plot an RNA feature
FeaturePlot(object = query, features = "GNLY", reduction = "proj.umap")
VlnPlot(object = query, features = "GNLY", group.by = predicted.id) + NoLegend()

# Plot an imputed protein feature
if (TRUE) {
  FeaturePlot(object = query, features = "CD3-1", reduction = "proj.umap")
  VlnPlot(object = query, features = "CD3-1", group.by = predicted.id) + NoLegend()
}

```

We load in the predicted cell types by Azimuth so that it can be compared to the annotations based on Amy's data.
```{r}
# load in the predicted cell types by Azimuth
azimuth.filepath<-"/home/yanxiting/Documents/Research/GRADS_SARC_PBMC/scRNA-seq/Seurat/azimuth/azimuth_pred.tsv"
azimuth.pred<-read_tsv(azimuth.filepath)
azimuth.pred<-as.data.frame(azimuth.pred)
rownames(azimuth.pred)<-as.character(azimuth.pred[,1])
```

#### Integrate with Amy's data

We obtained another PBMC 10X data annotated in Kaminski lab so that we can integrate this dataset with the annotated data to annotate the cells in this dataset. The seurat object containing the annotated PBMC 10x data is under /home/xy48/scratch_palmer/Amy_PBMC on grace hpc. We ran this section of codes on hpc.

##### data loading

We first load in the annotated PBMC 10x data from Amy.
```{r fig.width=10,fig.height=10}
my.distinct.colors<-c('#e6194b', '#3cb44b', '#ffe119', '#4363d8', '#f58231', '#911eb4', '#46f0f0', '#f032e6', '#bcf60c', '#fabebe', '#008080', '#e6beff', '#9a6324', '#fffac8', '#800000', '#aaffc3', '#808000', '#ffd8b1', '#000075', '#808080', '#ffffff', '#000000')

data.filepath<-"/home/yanxiting/driver_Grace/scratch_palmer/Amy_PBMC/01.03.23.controls.for.Xiting.rds"
amy.10x<-readRDS(data.filepath,refhook = NULL)
amy.10x<-subset(amy.10x,cells= rownames(amy.10x@meta.data)[!is.na(amy.10x@meta.data$SampleID)])
temp.num<-as.matrix(table(amy.10x@meta.data$SampleID))[,1]
amy.10x<-subset(amy.10x,cells=rownames(amy.10x@meta.data)[amy.10x@meta.data$SampleID%in%names(temp.num)[temp.num>=700]])

DefaultAssay(amy.10x)<-"integrated"
DimPlot(amy.10x, reduction = "umap",group.by="Annotation_090822",cols = my.distinct.colors)
DimPlot(amy.10x, reduction = "umap",group.by="SampleID",cols = my.distinct.colors)
```

We then load in the integrated seurat object of our data.

```{r}
data.filepath<-"/home/yanxiting/Documents/Research/GRADS_SARC_PBMC/scRNA-seq/Seurat/integrated_analysis/seurat_object_integrated_allcells_cellclustering_noSingleR.rds"
sample1.combined<-readRDS(data.filepath,refhook=NULL)
# focus on samples with >=700 cells in total
temp.num<-as.matrix(table(sample1.combined@meta.data$sample.names))[,1]
sample1.combined<-subset(sample1.combined,cells=rownames(sample1.combined@meta.data)[sample1.combined@meta.data$sample.names%in%names(temp.num)[temp.num>=700]])
```

##### Merge counts
Merge the raw count data from these two sources for integration analysis.

```{r}
temp.names<-intersect(rownames(sample1.combined@assays$RNA@counts),rownames(amy.10x@assays$RNA@counts))
merged.counts<-cbind(sample1.combined@assays$RNA@counts[temp.names,],amy.10x@assays$RNA@counts[temp.names,])
merged.metadata<-rbind(as.matrix(sample1.combined@meta.data[,c("disease","sample.names")]),as.matrix(amy.10x@meta.data[,c("disease","sampleID")]))
temp<-c(rep(NA,nrow(sample1.combined@meta.data)),amy.10x@meta.data$Annotation_090822)
merged.metadata<-cbind(merged.metadata,temp)
colnames(merged.metadata)[3]<-"Annotation_090822"
temp.pred<-c(rep(NA,nrow(sample1.combined@meta.data)),rep(NA,nrow(amy.10x@meta.data)))
names(temp.pred)<-c(rownames(sample1.combined@meta.data),rownames(amy.10x@meta.data))
temp.names<-intersect(rownames(sample1.combined@meta.data),rownames(azimuth.pred))
temp.pred[temp.names]<-azimuth.pred[temp.names,"predicted.celltype.l2"]

merged.metadata<-cbind(merged.metadata,temp.pred)
colnames(merged.metadata)[4]<-"Annotation_azimuth"

merged.data<-CreateSeuratObject(counts=merged.counts,project="MergedSeuratObject",assay="RNA",min.cells=3,min.features = 200)
merged.data[["percent.mt"]] <- PercentageFeatureSet(merged.data, pattern = "^MT-")

cat("\n")
cat("Originally, there are ",nrow(merged.counts)," genes and ",ncol(merged.counts)," cells in the data.\n",sep="")
cat("After the first step filtering, there are ",nrow(merged.data@assays$RNA@data)," genes and ",ncol(merged.data@assays$RNA@data)," cells in the filtered data.\n",sep="")

rm(merged.counts)
#gc(verbose=F)
invisible(gc())


merged.data <- AddMetaData(object = merged.data, metadata = merged.metadata[,"disease"], col.name = "disease")
merged.data <- AddMetaData(object = merged.data, metadata = merged.metadata[,"sample.names"], col.name = "sample.names")
merged.data <- AddMetaData(object = merged.data, metadata = merged.metadata[,"Annotation_090822"], col.name = "Annotation_090822")
merged.data <- AddMetaData(object = merged.data, metadata = merged.metadata[,"Annotation_azimuth"], col.name = "Annotation_azimuth")
temp<-rep("",nrow(merged.data@meta.data))
temp[substr(merged.data@meta.data$sample.names,1,1)=="G"]<-"courtney"
temp[substr(merged.data@meta.data$sample.names,1,1)=="C"]<-"amy"
merged.data <- AddMetaData(object = merged.data, metadata = temp, col.name = "study")

```

##### integration analysis
Split the whole dataset based on subject ID. Find anchors to integrate all the datasets together.

```{r}
sample1.raw<-merged.data
sample1.list<-SplitObject(sample1.raw,split.by="study")
#sample1.list<-SplitObject(sample1.raw,split.by="sample.names")
sample1.list<-lapply(X=sample1.list,FUN=function(x){
  x<-NormalizeData(x)
  x<-FindVariableFeatures(x,selection.method="vst",nfeatures=2000)
})
temp.cellnum<-unlist(lapply(sample1.list,ncol))

# increase the global maxSize
options(future.globals.maxSize= 40194304000)
features <- SelectIntegrationFeatures(object.list = sample1.list)
sample1.list <- lapply(X = sample1.list, FUN = function(x) {
    x <- ScaleData(x, features = features, verbose = FALSE)
    x <- RunPCA(x, features =features, npcs=40,verbose=F)
})
#sample1.anchors<-FindIntegrationAnchors(sample1.list[temp.cellnum>=92],k.filter=92,dims=1:40,verbose=FALSE)
sample1.anchors<-FindIntegrationAnchors(object.list=sample1.list,anchor.features=features, reduction="rpca",verbose=FALSE)
# reference=c(1,2): https://satijalab.org/seurat/archive/v3.2/integration.html
#sample1.combined<-IntegrateData(anchorset=sample1.anchors,features.to.integrate=rownames(sample1.raw@assays$RNA@counts),dims=1:40,verbose=FALSE)
#,k.filter=40,dims=1:40
merged.combined<-IntegrateData(anchorset=sample1.anchors,verbose=FALSE)

```



##### cell clustering
Cluster the cells using the integrated data.

```{r}
DefaultAssay(merged.combined) <- "integrated"
# Run the standard workflow for visualization and clustering
merged.combined <- ScaleData(merged.combined, verbose = FALSE)
merged.combined <- RunPCA(merged.combined, npcs = 40, verbose = FALSE)
# t-SNE and Clustering
merged.combined <- RunUMAP(merged.combined, reduction = "pca", dims = 1:40)
merged.combined <- FindNeighbors(merged.combined, reduction = "pca", dims = 1:40)
merged.combined <- FindClusters(merged.combined, resolution = 1.2)
```
##### data saving
We save the result in a rds file.
```{r}
home.dir<-"/home/yanxiting/Documents/Research/GRADS_SARC_PBMC"
output.dir<-file.path(home.dir,"scRNA-seq/Seurat")
temp<-file.path(output.dir,"integrated_amy")
if(file.exists(temp)==F){
  dir.create(temp)
}
output.filepath<-file.path(output.dir,"integrated_amy","seurat_object_integrated_merged_study.rds")
saveRDS(merged.combined,file=output.filepath)
cat("We saved the integrated data based on studies for all cells as ",output.filepath,"\n",sep="")
output.filepath<-file.path(output.dir,"integrated_amy","seurat_object_original_merged_study.rds")
saveRDS(merged.data,file=output.filepath)
cat("We saved the original merged count matrix based on studies for all cells as ",output.filepath,"\n",sep="")
```


##### visualization

Generate UMAPs of the Courtney and Amy datasets to compare the cell types predicted by Azimuth and by Amy.
```{r,fig.width=10,fig.height=10}
library(cowplot)
library(randomcoloR)
n <- 31
temp.colors.31 <- distinctColorPalette(n)

temp.ct<-merged.combined@meta.data$Annotation_090822
temp.ct[is.na(temp.ct)]<-merged.combined@meta.data$Annotation_azimuth[is.na(temp.ct)]
merged.combined<-AddMetaData(merged.combined,metadata=temp.ct,col.name="ct.pred")

p1<-DimPlot(merged.combined, reduction = "umap", cells=rownames(merged.combined@meta.data)[merged.combined@meta.data$study=="courtney"],group.by="ct.pred",shuffle = TRUE,cols = temp.colors.31)+labs(title = "Courtney (Azimuth)")
p2<-DimPlot(merged.combined, reduction = "umap", cells=rownames(merged.combined@meta.data)[merged.combined@meta.data$study=="amy"],group.by="ct.pred",shuffle=TRUE,cols = temp.colors.31)+labs(title = "Amy (Annotated)")

#DimPlot(merged.combined, reduction = "umap", group.by="sample.names",label = TRUE,split.by="study")
#DimPlot(merged.combined, reduction = "umap", group.by="Annotation_090822", label = TRUE,cols=my.distinct.colors,split.by="study")
#p4<-DimPlot(merged.combined, reduction = "umap", group.by="singler.hpca.cluster", label = TRUE,cols=my.distinct.colors)
#p5<-DimPlot(merged.combined, reduction = "umap", group.by="disease", label = TRUE,cols=my.distinct.colors)
grid.arrange(p1,p2,ncol=1)
```

```{r,fig.width=10,fig.height=14}
p1<-DimPlot(merged.combined, reduction = "umap", cells=rownames(merged.combined@meta.data)[merged.combined@meta.data$study=="courtney"],group.by="ct.pred",shuffle = TRUE,cols = temp.colors.31,label = TRUE)+labs(title = "Courtney (Azimuth)")
p2<-DimPlot(merged.combined, reduction = "umap", cells=rownames(merged.combined@meta.data)[merged.combined@meta.data$study=="amy"],group.by="ct.pred",shuffle=TRUE,cols = temp.colors.31,label=TRUE)+labs(title = "Amy (Annotated)")

#DimPlot(merged.combined, reduction = "umap", group.by="sample.names",label = TRUE,split.by="study")
#DimPlot(merged.combined, reduction = "umap", group.by="Annotation_090822", label = TRUE,cols=my.distinct.colors,split.by="study")
#p4<-DimPlot(merged.combined, reduction = "umap", group.by="singler.hpca.cluster", label = TRUE,cols=my.distinct.colors)
#p5<-DimPlot(merged.combined, reduction = "umap", group.by="disease", label = TRUE,cols=my.distinct.colors)
grid.arrange(p1,p2,ncol=1)
```





#old
Visualize the integrated data by splitting it to different clusters.

```{r,fig.width=10,fig.height=50}
fig.list<-list()
celltype.names<-as.numeric(unique(as.character(Idents(sample1.combined))))
celltype.names<-sort(celltype.names,decreasing=F)
for(i in 1:length(celltype.names)){
  temp.map<-as.character(Idents(sample1.combined))
  temp.map[temp.map!=celltype.names[i]]="other"
  sample1.combined@meta.data$temp.map<-temp.map
  fig.list[[2*(i-1)+1]]<-DimPlot(sample1.combined, reduction = "umap", label = FALSE,group.by="ident")
  #fig.list[[2*i]]<-DimPlot(sample1.combined, reduction = "umap", label = FALSE,group.by="temp.map",cols=c(my.distinct.colors[i],"grey"))
  fig.list[[2*i]]<-DimPlot(sample1.combined, reduction = "umap", label = FALSE,group.by="temp.map",cols=c("red","grey"))
}
do.call(grid.arrange,c(fig.list,ncol=2))
```

Visualize the integrated data by splitting it to different subjects and different cell type annotation (old).

```{r,fig.width=16,fig.height=24}
fig.list<-list()
celltype.names<-unique(as.character(sample1.combined@meta.data$singler.hpca.cluster))
celltype.names<-sort(celltype.names,decreasing=T)
for(i in 1:length(celltype.names)){
  temp.map<-as.character(sample1.combined@meta.data$singler.hpca.cluster)
  temp.map[temp.map!=celltype.names[i]]<-"zother"
  sample1.combined@meta.data$temp.map<-temp.map
  fig.list[[i]]<-DimPlot(sample1.combined, reduction = "umap",group.by="temp.map",label = FALSE,pt.size=0.5,cols=c(my.distinct.colors[i],"grey"))
}
do.call(grid.arrange,c(fig.list,ncol=2))
```

#### Cell typing using SingleR annotation

We run SingleR (v 1.2.0) again based on the clustering results based on the integrated data and visualize the data using the new cell typing annotation.

```{r fig.width=12,fig.height=8}
# run SingleR with HPCA as reference dataset.
library(SingleR)
library(scRNAseq)
library(scater)
hpca.se <- HumanPrimaryCellAtlasData()
hpca.se
#hESCs <- LaMannoBrainData('human-es')
my.temp<-CreateSeuratObject(counts=sample1.combined@assays$RNA@counts,project = "ChuppSputum",min.cells = 0,  min.features = 0)
temp<-as.SingleCellExperiment(my.temp,assay="RNA")
temp<-logNormCounts(temp)
sample1.singler.hpca<-SingleR(test=temp,ref=hpca.se,labels=hpca.se$label.fine,method="cluster",clusters=as.character(Idents(sample1.combined)))
plotScoreHeatmap(sample1.singler.hpca)
```


Data visulization labelled by the new SingleR results on the combined data.
```{r}
cluster.names<-rownames(sample1.singler.hpca)
cluster.labels<-sample1.singler.hpca$pruned.labels
temp.map<-as.character(Idents(sample1.combined))
temp.map<-plyr::mapvalues(x=temp.map,from=cluster.names,to=cluster.labels)
sample1.combined<-AddMetaData(sample1.combined,metadata=temp.map,col.name="singler.hpca.cluster.combined")
```


Get the main cell type labels and save the annotated seurat R object.
```{r}
# get the main labels
my.temp<-CreateSeuratObject(counts=sample1.combined@assays$RNA@counts,project = "ChuppSputum",min.cells = 0,  min.features = 0)
temp<-as.SingleCellExperiment(my.temp,assay="RNA")
temp<-logNormCounts(temp)
sample1.singler.hpca<-SingleR(test=temp,ref=hpca.se,labels=hpca.se$label.main,method="cluster",clusters=as.character(Idents(sample1.combined)))
plotScoreHeatmap(sample1.singler.hpca)
```


```{r}
cluster.names<-rownames(sample1.singler.hpca)
cluster.labels<-sample1.singler.hpca$pruned.labels
temp.map<-as.character(Idents(sample1.combined))
temp.map<-plyr::mapvalues(x=temp.map,from=cluster.names,to=cluster.labels)
sample1.combined<-AddMetaData(sample1.combined,metadata=temp.map,col.name="singler.hpca.cluster.main.combined")
output.filepath<-file.path(output.subdir,"seurat_object_integrated_allcells_cellclustering_singler_hpca.rds")
saveRDS(sample1.combined,file=output.filepath)
```

Visulizing the SingleR cell typing results on the combined UMAP.
```{r,fig.width=14,fig.height=24}
fig.list<-list()
celltype.names<-unique(as.character(sample1.combined@meta.data$singler.hpca.cluster.combined))
celltype.names<-sort(celltype.names,decreasing=T)
for(i in 1:length(celltype.names)){
  temp.map<-as.character(sample1.combined@meta.data$singler.hpca.cluster.combined)
  temp.map[temp.map!=celltype.names[i]]<-"zother"
  sample1.combined@meta.data$temp.map<-temp.map
  fig.list[[i]]<-DimPlot(sample1.combined, reduction = "umap",group.by="temp.map",label = FALSE,pt.size=0.5,cols=c(my.distinct.colors[i],"grey"))
}
do.call(grid.arrange,c(fig.list,ncol=2))
```


